{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 10-11: Деревья Решений и Случайный Лес на практике\n",
    "\n",
    "**Цель семинара:** Показать полный цикл работы с древовидными моделями на двух разных типах задач: классификации и регрессии. Сделать акцент на визуализации, интерпретации и сравнении одиночного дерева с ансамблем.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Задача Классификации\n",
    "\n",
    "**Датасет:** `penguins_size.csv` — данные о пингвинах. Простой и чистый, отлично подходит для визуализации.\n",
    "**Цель:** Научиться предсказывать вид пингвина (`species`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/data/penguins_size.csv')\n",
    "# Удаляем строки с пропусками для простоты\n",
    "df = df.dropna()\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Анализ и подготовка данных\n",
    "\n",
    "**Комментарий:** *Посмотрим на данные. `pairplot` отлично показывает, как признаки соотносятся друг с другом в разрезе классов. Видно, что некоторые пары признаков почти идеально разделяют классы, что является хорошим знаком для древовидных моделей.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** *Деревьям нужны числовые данные. Преобразуем категориальные признаки (`island`, `sex`) в числа с помощью `pd.get_dummies`. Затем разделим данные на обучающую и тестовую выборки. Обратите внимание, что **масштабирование (`StandardScaler`) не требуется**, так как деревья работают с порогами и нечувствительны к масштабу.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.get_dummies(df.drop('species', axis=1), drop_first=True)\n",
    "y = df['species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Модель 1: Одно Дерево Решений\n",
    "\n",
    "**Комментарий:** *Обучим `DecisionTreeClassifier` с параметрами по умолчанию, чтобы увидеть, на что он способен \"из коробки\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=101)\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "dt_preds = dt_model.predict(X_test)\n",
    "\n",
    "print(\"--- Результаты Decision Tree ---\")\n",
    "print(classification_report(y_test, dt_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** *Теперь самое интересное — визуализируем дерево. Оно получилось очень большим и сложным. Это наглядная демонстрация **переобучения**: модель создала очень специфичные правила, чтобы идеально классифицировать каждый объект в обучающей выборке. На новых данных такая сложная модель может работать хуже.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(dt_model, feature_names=X.columns, filled=True)\n",
    "plt.title(\"Переобученное дерево решений\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Модель 2: Случайный Лес\n",
    "\n",
    "**Комментарий:** *Теперь применим `RandomForestClassifier`. Это ансамбль из множества таких деревьев. Ожидаем, что результат будет более стабильным и точным.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=101)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_preds = rf_model.predict(X_test)\n",
    "\n",
    "print(\"--- Результаты Random Forest ---\")\n",
    "print(classification_report(y_test, rf_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** *Случайный лес позволяет оценить **важность признаков** — какой вклад каждый признак вносит в итоговое предсказание. Это усредненная оценка по всем деревьям ансамбля.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.DataFrame(index=X.columns, data=rf_model.feature_importances_, columns=['Importance'])\n",
    "importances = importances.sort_values('Importance', ascending=False)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод по части 1:** *Случайный лес показал более высокую точность, чем одно дерево. Он также дал нам более надежную оценку важности признаков, показав, что длина и высота клюва — самые важные предикторы вида пингвина.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Задача Регрессии\n",
    "\n",
    "**Датасет:** Синтетические данные на основе функции `cos(x)` с добавлением шума.\n",
    "**Цель:** Увидеть, как дерево и лес аппроксимируют гладкую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем данные\n",
    "x_range = np.linspace(0, 10, 100)\n",
    "noise = np.random.randn(len(x_range)) * 0.2\n",
    "y_reg = np.cos(x_range) + noise\n",
    "\n",
    "X_reg = x_range.reshape(-1, 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_reg, y_reg, label='Данные с шумом')\n",
    "plt.plot(x_range, np.cos(x_range), 'r--', label='Истинная функция cos(x)')\n",
    "plt.legend()\n",
    "plt.title(\"Синтетические данные для задачи регрессии\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Модель 1: Дерево Регрессии\n",
    "\n",
    "**Комментарий:** *Обучим `DecisionTreeRegressor` с ограниченной глубиной (`max_depth=3`), чтобы его предсказания были наглядными.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(max_depth=3)\n",
    "dt_reg.fit(X_reg, y_reg)\n",
    "\n",
    "dt_reg_preds = dt_reg.predict(X_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** *Визуализируем результат. Предсказание дерева — это **ступенчатая функция**. Каждый \"шаг\" соответствует среднему значению в листе дерева.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_reg, y_reg, alpha=0.5, label='Данные')\n",
    "plt.plot(x_range, dt_reg_preds, 'g-', label='Предсказания Decision Tree (max_depth=3)')\n",
    "plt.legend()\n",
    "plt.title(\"Аппроксимация деревом регрессии\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Модель 2: Случайный Лес для Регрессии\n",
    "\n",
    "**Комментарий:** *Теперь обучим `RandomForestRegressor`. Его предсказание будет средним от сотен таких ступенчатых функций.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=100)\n",
    "rf_reg.fit(X_reg, y_reg)\n",
    "\n",
    "rf_reg_preds = rf_reg.predict(X_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарий:** *Сравним предсказания дерева и леса на одном графике. Предсказание леса гораздо более гладкое и лучше следует за истинной функцией, игнорируя шум.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X_reg, y_reg, alpha=0.3, label='Данные')\n",
    "plt.plot(x_range, dt_reg_preds, 'g-', label='Decision Tree (max_depth=3)', linewidth=2)\n",
    "plt.plot(x_range, rf_reg_preds, 'm-', label='Random Forest', linewidth=2)\n",
    "plt.plot(x_range, np.cos(x_range), 'r--', label='Истинная функция cos(x)')\n",
    "plt.legend()\n",
    "plt.title(\"Сравнение Дерева и Случайного Леса в регрессии\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итоговый вывод семинара:** *Мы убедились, что древовидные модели можно применять как для классификации, так и для регрессии. В обоих случаях ансамблевый подход в лице Случайного Леса показывает более качественные и стабильные результаты, чем одно дерево решений, эффективно борясь с переобучением.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
