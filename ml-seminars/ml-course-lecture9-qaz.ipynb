{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дәріс 9: Метрикалық әдістер (KNN) және Тірек векторлар әдісі (SVM)\n",
    "\n",
    "**Дәріс мақсаты:**\n",
    "1.  **K-ең жақын көршілер (KNN)** мысалында классификацияның **метрикалық әдістерімен** танысу.\n",
    "2.  Ең қуатты классикалық алгоритмдердің бірі — **Тірек векторлар әдісін (SVM)** зерттеу.\n",
    "3.  Осы алгоритмдердің негізінде жатқан математикалық негіздерді талдау.\n",
    "4.  Python және Scikit-Learn кітапханасын қолдана отырып, бинарлық және көп класты классификация есептерінде осы модельдерді қолдануды, баптауды және салыстыруды үйрену."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-бөлім: K-ең жақын көршілер әдісі (K-Nearest Neighbors, KNN)\n",
    "\n",
    "KNN **метрикалық алгоритмдерге** жатады, олардың негізінде **ықшамдылық гипотезасы** жатыр. Ол бойынша, бір класқа жататын нысандар белгілер кеңістігінде бір-біріне жақын орналасып, \"ықшам\" кластерлер құрайды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Интуиция және математикалық негіздер\n",
    "\n",
    "KNN интуициясы өте қарапайым: **жаңа нысанның класы оның ең жақын көршілері арасында қай класстың басым екеніне байланысты анықталады.**\n",
    "\n",
    "![k=3](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/knn_illustration_k3.png)\n",
    "![k=5](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/knn_illustration_k5.png)\n",
    "\n",
    "\"Ең жақын\" көршілерді табу үшін бізге қашықтықты өлшей білу керек. Ол үшін [**метрикалар**](http://lightcone.ru/manhattan/?ysclid=mhu3mmwtkq673949565) қолданылады\n",
    "\n",
    "#### Минковский метрикасы\n",
    "Бұл n-өлшемді кеңістіктегі екі $x$ және $x_i$ векторлары арасындағы қашықтықтың жалпыланған метрикасы. Ол келесі түрге ие:\n",
    "\n",
    "$$ p(x, x_i) = \\left( \\sum_{j=1}^{n} \\omega_j |x^j - x_i^j|^p \\right)^{1/p} $$\n",
    "\n",
    "мұндағы:\n",
    "- $n$ — белгілер саны (кеңістік өлшемі).\n",
    "- $p > 0$ — метриканың түрін анықтайтын параметр.\n",
    "- $\\omega_j$ — белгілердің салмақтары. Олар белгілердің әртүрлі масштабы немесе маңыздылығы болғанда маңызды. Іс жүзінде, белгілердің әсерін теңестіру үшін деректерді әрқашан **масштабтайды**.\n",
    "\n",
    "![Разница между метриками расстояния](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/distance_metrics.png)\n",
    "\n",
    "Минковский метрикасының екі ең танымал жеке жағдайы:\n",
    "\n",
    "1.  **Евклидтік қашықтық (p=2 болғанда):** Бізге үйреншікті \"тікелей\" қашықтық.\n",
    "$$ p(x, x_i) = \\sqrt{ \\sum_{j=1}^{n} (x^j - x_i^j)^2 } $$\n",
    "\n",
    "2.  **Манхэттендік қашықтық (p=1 болғанда):** \"Қалалық кварталдар қашықтығы\", координаталар айырмашылықтарының модульдерінің қосындысы.\n",
    "$$ p(x, x_i) = \\sum_{j=1}^{n} |x^j - x_i^j| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. KNN алгоритмі\n",
    "\n",
    "Жаңа $x$ нысанын жіктеу үшін алгоритм келесі қадамдарды орындайды:\n",
    "1.  **K таңдау** — біз сүйенетін көршілер саны.\n",
    "2.  **Қашықтықтарды есептеу** — таңдалған метрика арқылы $x$-тен оқыту жиынтығындағы әрбір $x_i$ нысанына дейінгі қашықтықты есептеу.\n",
    "3.  **K көршіні табу** — оқыту жиынтығынан $x$-ке ең аз қашықтықта орналасқан K нысанды таңдау.\n",
    "4.  **Класты анықтау** — $x$ нысанының класы табылған K көршілер арасында басым болатын класс бойынша анықталады (көпшілік дауыс беру).\n",
    "\n",
    "Математикалық тұрғыдан, егер $y^{(i)}$ — $k$ ең жақын көршінің $i$-ші көршісінің класы болса, онда жаңа нысанның $a(x)$ класы былай табылады:\n",
    "\n",
    "$$ a(x, X^l) = \\arg\\max_{y \\in Y} \\sum_{i=1}^{k} [y^{(i)} = y] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. KNN артықшылықтары мен кемшіліктері\n",
    "\n",
    "#### Артықшылықтары:\n",
    "*   **Қарапайымдылық және интуитивтілік:** Алгоритмді түсіну және жүзеге асыру оңай.\n",
    "*   **Икемділік:** Регрессия есептеріне оңай бейімделеді (көршілердің мәндерін орташалау арқылы, ол үшін `scikit-learn`-де **`KNeighborsRegressor`** модулі қолданылады).\n",
    "*   **Оқыту кезеңі жоқ:** KNN \"жалқау\" алгоритм болып табылады. Ол модель құрмайды, тек бүкіл оқыту жиынтығын жаттап алады. Оқыту лезде жүреді.\n",
    "\n",
    "#### Кемшіліктері:\n",
    "*   **Болжау кезеңіндегі есептеу күрделілігі:** Бір жаңа нысанды жіктеу үшін оқыту жиынтығындағы барлық нысандарға дейінгі қашықтықты есептеу керек, бұл үлкен деректерде өте баяу болуы мүмкін.\n",
    "*   **Белгілердің масштабына сезімталдығы:** Деректерді міндетті түрде масштабтауды қажет етеді.\n",
    "*   **K таңдауына сезімталдығы:** Нәтиже осы гиперпараметрге қатты тәуелді.\n",
    "*   **Жадқа талапшылдық:** Бүкіл оқыту жиынтығын сақтау қажет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-бөлім: Тірек векторлар әдісі (Support Vector Machines, SVM)\n",
    "\n",
    "SVM — ең қуатты және танымал жіктеу алгоритмдерінің бірі. Оның негізгі идеясы — жай ғана бөлу шекарасын емес, **оңтайлы бөлуші гипержазықтықты** табу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Интуиция және математикалық негіздер\n",
    "\n",
    "#### Гипержазықтық\n",
    "Гипержазықтық — бұл түзудің (2D үшін) және жазықтықтың (3D үшін) кез келген өлшемді кеңістікке жалпылануы. Бұл өлшемі бастапқы кеңістіктен бірге кем ішкі кеңістік.\n",
    "\n",
    "![Примеры гиперплоскостей в разных размерностях](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/hyperplanes.png)\n",
    "\n",
    "Гипержазықтық теңдеуі келесі түрде беріледі:\n",
    "\n",
    "$$ w^T x - b = 0 \\quad \\text{немесе} \\quad \\langle w, x \\rangle - b = 0 $$\n",
    "\n",
    "мұндағы:\n",
    "- $w$ — оның бағытын анықтайтын салмақтар векторы (гипержазықтыққа нормаль).\n",
    "- $x$ — нысанның белгілер векторы.\n",
    "- $b$ — гипержазықтықтың орналасуын анықтайтын ығысу (bias).\n",
    "\n",
    "#### Аралықты (Margin) барынша арттыру\n",
    "SVM әр класстың ең жақын нысандарынан максималды қашықтықта орналасқан гипержазықтықты іздейді. Бұл аралық **margin** деп аталады. Осы аралықтың шекараларында жатқан нысандар **тірек векторлар** (support vectors) деп аталады, өйткені дәл солар гипержазықтықты \"қолдап\", оның орналасуын анықтайды.\n",
    "\n",
    "![Оптимальная разделяющая гиперплоскость](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/оптимальная_разделяющая_гиперплоскость.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сызықтық бөлінетін** жағдай үшін SVM есебі квадраттық бағдарламалау есебіне келеді: біз барлық нүктелердің дұрыс жіктелгені шартымен салмақтар векторының нормасын **минималдауды** (бұл аралықты максималдауға тең) қалаймыз.\n",
    "\n",
    "$$ \\frac{1}{2} ||w||^2 \\rightarrow \\min_{w,b} $$\n",
    "Шектеу кезінде:\n",
    "$$ y_i(\\langle w, x_i \\rangle - b) \\ge 1, \\quad i=1, \\dots, l $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Бұл формуланы талдап көрейік:**\n",
    "1.  **$\\langle w, x_i \\rangle - b$ өрнегі** — бұл $x_i$ нүктесі үшін \"есеп\". Оның таңбасы нүктенің орталық сызықтан қай жақта екенін көрсетеді.\n",
    "2.  **$y_i$-ге көбейту** (класс белгісі, `+1` немесе `-1`) — бұл бір айла. Егер нүкте дұрыс жіктелсе, осы көбейтіндінің нәтижесі әрқашан оң болады.\n",
    "3.  **$\\ge 1$ талабы** — ең бастысы. Біз әр нүктенің орталықтан дұрыс жақта (`> 0`) ғана емес, өз аралығының шекарасында (`= 1`) немесе одан да алыс (`> 1`) болуын талап етеміз. Бұл кластар арасында \"бос аймақ\" жасайды, оның енін біз барынша арттыруға тырысамыз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. \"Тірек Векторлар\" деген не?\n",
    "\n",
    "\"Тірек Векторлар Әдісі\" атауы өзі-өзіне жауап беріп тұр. **Тірек векторлар** — бұл оңтайлы бөлуші гипержазықтықтың орналасуы мен бағытын анықтайтын оқыту жиынтығындағы негізгі нүктелер.\n",
    "\n",
    "**Тұжырымдама:** Үстелдегі екі түрлі тиынды сызғышпен бөліп жатырсыз деп елестетіңіз. Аралық максималды болуы үшін, сіз сызғышты екі жақтан да бірнеше тиынға тірелгенше жылжытасыз. Сызғышты \"тіреп тұрған\" осы тиындар — **тірек векторлар**. Алыста орналасқан қалған барлық тиындар сызғыштың орналасуына әсер етпейді.\n",
    "\n",
    "**Анықтама:**\n",
    "1.  **Идеалды жағдайда (Hard Margin):** Тірек векторлар болып тек **дәл аралықтың шекараларында жатқан** нүктелер саналады (мұнда $ y_i(\\langle w, x_i \\rangle - b) = 1 $).\n",
    "2.  **Нақты жағдайда (Soft Margin):** Тірек векторлар болып **барлық бұзушы-нүктелер** саналады: аралықтың шекарасында, оның ішінде жатқандар немесе дұрыс жіктелмегендер.\n",
    "\n",
    "**Бұл неліктен маңызды?**\n",
    "- **Тиімділік:** Оқытудан кейін SVM моделі жадында бүкіл оқыту жиынтығын емес, **тек тірек векторларды** сақтайды. Жаңа нысанды болжау үшін ол оны **тек осы тірек векторлармен** салыстырады, бұл SVM-ді болжау кезеңінде өте жылдам етеді."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Жұмсақ аралық (Soft Margin) және бөлінбейтін деректер\n",
    "Шындығында, деректерді мінсіз бөлуге жиі болмайды. Мұндай жағдайлар үшін \"жұмсақ аралық\" тұжырымдамасы енгізіледі. Біз кейбір нүктелерге аралық шекараларын бұзуға немесе тіпті дұрыс жіктелмеуге рұқсат етеміз.\n",
    "\n",
    "![Пример мягкого зазора (Soft Margin)](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/пример_мягкого_зазора_(soft_margin).png)\n",
    "\n",
    "Бұл үшін $i$-ші нысанның шекараны қаншалықты бұзатынын көрсететін **әлсіз айнымалылар** (slack variables) $\\xi_i \\ge 0$ енгізіледі.\n",
    "\n",
    "Оңтайландыру есебі күрделенеді: енді біз тек салмақтар векторының нормасын ғана емес, сонымен қатар жалпы қатені ($\\xi_i$ қосындысын) де минималдаймыз:\\n$$ \\frac{1}{2} ||w||^2 + C \\sum_{i=1}^{l} \\xi_i \\rightarrow \\min_{w,b,\\xi} $$\n",
    "Шектеу әлсірейді:\n",
    "$$ y_i(\\langle w, x_i \\rangle - b) \\ge 1 - \\xi_i, \\quad \\xi_i \\ge 0, \\quad i=1, \\dots, l $$\n",
    "\n",
    "*   Егер $\\xi_i = 0$ болса, нүкте аралықтың сыртында орналасқан (бәрі дұрыс).\n",
    "*   Егер $0 < \\xi_i \\le 1$ болса, нүкте аралықтың ішіне түскен, бірақ дұрыс жіктелген.\n",
    "*   Егер $\\xi_i > 1$ болса, нүкте дұрыс жіктелмеген.\n",
    "\n",
    "Модель бір уақытта **аралықты максималдауға** ($||w||^2$-ны минималдау) және **жалпы қатені минималдауға** ($\\sum \\xi_i$-ны минималдау) тырысады. Осы екі мақсат арасындағы тепе-теңдік **`C` гиперпараметрімен** бақыланады.\n",
    "\n",
    "**`C` гиперпараметрі** — бұл реттеу (регуляризация) параметрі. Ол аралықты максималдау мен қателер санын минималдау арасындағы тепе-теңдікті бақылайды:\n",
    "- **Кішкентай `C`**: Біз оқыту жиынтығында көбірек қателіктерге әкелсе де, кең аралықты қалаймыз. Модель қарапайым, қайта оқытуға аз бейім (жоғары ығысу, төмен дисперсия).\n",
    "- **Үлкен `C`**: Біз қателіктер үшін қатты айыппұл саламыз, сондықтан модель әр нүктені аралықты тарылту арқылы болса да, дұрыс жіктеуге тырысады. Модель күрделірек және қайта оқытуға бейім (төмен ығысу, жоғары дисперсия)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ядро айласы (Kernel Trick)\n",
    "\n",
    "Егер деректер жұмсақ аралықпен де бөлінбейтін болса (мысалы, бір класс екіншісінің ішінде орналасқан)? Идея деректерді өлшемі жоғарырақ белгілер кеңістігіне ауыстыруда, онда олар сызықтық бөлінетін болуы мүмкін.\n",
    "\n",
    "![Визуализация трюка с ядром](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/kernel_trick_visualization.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM қалай болжам жасайды (Екі жақты форма)\n",
    "\n",
    "SVM болжау формуласын $w$ векторына емес, тікелей тірек векторларға тәуелді түрде жазуға болады екен:\n",
    "\n",
    "$$ \\text{болжау}(x) = \\text{sign} \\left( \\sum_{i \\in SV} \\alpha_i y_i \\langle x_i, x \\rangle - b \\right) $$\n",
    "\n",
    "мұндағы:\n",
    "- $x$ — біз жіктегіміз келетін жаңа нысан.\n",
    "- $x_i$ — модель оқыту кезінде жаттап алған $i$-ші **тірек вектор**.\n",
    "- $\\alpha_i$ және $y_i$ — осы тірек вектордың салмағы мен класы.\n",
    "- $\\langle x_i, x \\rangle$ — жаңа нысанның $i$-ші тірек векторға \"ұқсастығын\" өлшейтін скалярлық көбейтінді.\n",
    "\n",
    "**Қарапайым сөзбен:** жаңа нысанды жіктеу үшін, SVM оның жаттап алынған тірек векторлардың әрқайсысына ұқсастығын өлшейді, осы ұқсастықтарды салмақтармен қосады және қорытынды таңба негізінде шешім шығарады."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ядро деген не?\n",
    "\n",
    "**Ядро — бұл есептеу айласы.** Бұл $K(x_i, x)$ функциясы, ол бізге жаңа, өте күрделі кеңістіктегі скалярлық көбейтіндінің нәтижесін алуға мүмкіндік береді, **осы кеңістікке түрлендіруді орындамай-ақ.**\n",
    "\n",
    "Біз болжау формуласындағы $\\langle x_i, x \\rangle$-ты жай ғана $K(x_i, x)$-ке ауыстырамыз:\n",
    "\n",
    "$$ \\text{болжау}(x) = \\text{sign} \\left( \\sum_{i \\in SV} \\alpha_i y_i K(x_i, x) - b \\right) $$\n",
    "\n",
    "**Танымал ядролар:**\n",
    "1.  **Сызықтық:** $K(x_i, x) = \\langle x_i, x \\rangle$.\n",
    "2.  **Полиномдық:** $K(x_i, x_j) = (\\gamma \\langle x_i, x_j \\rangle + r)^d$. Гиперпараметрлер: $d$ дәрежесі, $\\gamma$ коэффициенті, $r$ бос мүшесі.\n",
    "3.  **Радиалды базистік функция (RBF):** $K(x_i, x) = \\exp(-\\gamma ||x_i - x||^2)$. Гаусс функциясы негізінде \"ұқсастықты\" есептейді. `gamma` параметрімен бақыланады. Кішкентай `gamma` үлкен әсерді білдіреді (тегіс шекара), үлкен `gamma` — жергілікті әсерді білдіреді (өте күрделі, ирек шекара)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. 'Ядро айласының' іс жүзіндегі демонстрациясы\n",
    "\n",
    "Қарапайым, көрнекі мысал арқылы ядролардың неліктен соншалықты маңызды екенін көрейік. Біз түзу сызықпен бөлу мүмкін емес синтетикалық деректер жиынтығын жасаймыз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Деректерді жасаймыз: бір класс (0) екінші класстың (1) ішінде шеңбер түрінде\n",
    "X, y = make_circles(n_samples=100, noise=0.1, factor=0.5, random_state=42)\n",
    "\n",
    "# Визуализациялаймыз\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='winter')\n",
    "plt.title('Сызықтық бөлінбейтін деректер (шеңберлер)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Көріп отырғанымыздай, бұл деректерді бір түзу сызықпен бөлу мүмкін емес. Екі түрлі ядросы бар SVM-ді оқытып көрейік.\n",
    "\n",
    "**№1 талпыныс: Сызықтық ядро**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Бөлу бетін сызуға арналған көмекші функция\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                           np.linspace(y_min, y_max, 100))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='winter')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='winter', edgecolors='k')\n",
    "    plt.title(f'Ядро: {model.kernel}')\n",
    "\n",
    "# Сызықтық ядромен модельді оқытамыз\n",
    "linear_svm = SVC(kernel='linear').fit(X, y)\n",
    "\n",
    "# Нәтижені визуализациялаймыз\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_decision_boundary(linear_svm, X, y)\n",
    "plt.show()\n",
    "print(f\"Сызықтық SVM дәлдігі: {linear_svm.score(X,y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сызықтық ядро сәтсіздікке ұшырады. Модель кластарды нашар бөлетін түзу сызық жүргізді, және дәлдік өте төмен.\n",
    "\n",
    "**№2 талпыныс: Сызықтық емес RBF ядросы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF ядросымен модельді оқытамыз (әдепкі бойынша қолданылады)\n",
    "rbf_svm = SVC(kernel='rbf', C=1, gamma='auto').fit(X, y)\n",
    "\n",
    "# Нәтижені визуализациялаймыз\n",
    "plt.figure(figsize=(8, 6))\n",
    "plot_decision_boundary(rbf_svm, X, y)\n",
    "plt.show()\n",
    "print(f\"RBF SVM дәлдігі: {rbf_svm.score(X,y):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Қорытынды:** RBF ядросы тапсырманы сәтті орындады! Ол кластарды мінсіз бөлген сызықтық емес, шеңберлі шекара салды, және дәлдік 100% болды. Бұл мысал \"ядро айласының\" SVM-ге бір ғана гиперпараметрді өзгерту арқылы күрделі, сызықтық емес есептерді шешуге қалай мүмкіндік беретінін айқын көрсетеді."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. SVM артықшылықтары мен кемшіліктері\n",
    "\n",
    "#### Артықшылықтары:\n",
    "*   **Жоғары өлшемді кеңістіктердегі тиімділік:** Белгілер көп болғанда тамаша жұмыс істейді.\n",
    "*   **Жад бойынша тиімділік:** Модель құру үшін оқыту нүктелерінің тек бір бөлігін (тірек векторларды) пайдаланады.\n",
    "*   **Икемділік:** Ядролардың арқасында өте күрделі сызықтық емес бөлу беттерін құра алады.\n",
    "*   **Берік математикалық негіздемесі бар**, дөңес оңтайландыру есебі түрінде, бұл ғаламдық минимумды табуға кепілдік береді.\n",
    "\n",
    "#### Кемшіліктері:\n",
    "*   **Ядроны және оның гиперпараметрлерін (`C`, `gamma`) таңдауға сезімталдығы:** `GridSearchCV` көмегімен мұқият таңдауды қажет етеді.\n",
    "*   **Есептеу күрделілігі:** Өте үлкен деректер жиындарында оқыту ұзақ болуы мүмкін.\n",
    "*   **Түсіндірудің қиындығы:** Сызықтық емес ядросы бар модель \"қара жәшік\" болып табылады, оның шешімдерін түсіндіру қиын."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Регрессия есептері үшін SVM-ді қолдану (SVR)\n",
    "\n",
    "Тірек векторлар әдісін регрессия есептерін шешу үшін де талғампаз түрде бейімдеуге болады. Бұл тәсіл **Тірек-векторлық регрессия (Support Vector Regression, SVR)** деп аталады.\n",
    "\n",
    "#### Интуиция: \"максималды аралықтан\" \"мүмкіндігінше кең көшеге\" дейін\n",
    "\n",
    "Еске түсірейік, классификацияда SVM кластар арасында **максималды аралыққа** ие болатын гипержазықтықты іздеді. Регрессияда кластар жоқ, бізде үздіксіз мақсатты айнымалы бар.\n",
    "\n",
    "SVR-дің негізгі идеясы — керісінше әрекет ету. Нүктелерді бір-бірінен алшақтатудың орнына, біз айналасында мүмкіндігінше көп нүктелері бар \"көше\" немесе \"дәліз\" құруға болатын функцияны (гипержазықтықты) тапқымыз келеді.\n",
    "\n",
    "* **Мақсат:** Регрессия сызығын көптеген нүктелерге мүмкіндігінше жақын болатындай етіп жүргізу.  \n",
    "* **\"Көше\" (Дәліз):** Біз регрессия сызығымыздың айналасында ені $2ε$ (екі эпсилон) болатын дәлізді анықтаймыз.  \n",
    "* **Ереже:** Егер деректер нүктелері осы дәліздің **ішіне** түссе, біз модельге **айыппұл салмаймыз**. Айыппұл тек **сыртта** қалған нүктелер үшін ғана есептеледі.\n",
    "\n",
    "![SVR жұмыс істеу принципі](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/svr_illustration.png)\n",
    "\n",
    "#### Математикалық қойылым\n",
    "\n",
    "SVR есебі, SVM сияқты, дөңес оңтайландыру есебіне келеді. Біз тағы да салмақтар векторының $||w||^2$ нормасын минималдауды қалаймыз (бұл модельді \"тегіс\" етеді), бірақ басқа шектеулермен.\n",
    "\n",
    "Біз $ε$-нан аз ауытқуларды \"кешіре отырып\", нақты $y_i$ мәндерінен ең аз ауытқуы бар $f(x) = \\langle w, x \\rangle + b$ функциясын тапқымыз келеді.\n",
    "\n",
    "Бұл келесі минималдау есебіне әкеледі (\"бастапқы\" форма):\n",
    "\n",
    "$$ \\frac{1}{2} ||w||^2 + C \\sum_{i=1}^{l} (\\xi_i + \\xi_i^*) \\rightarrow \\min_{w,b,\\xi,\\xi^*} $$\n",
    "\n",
    "Шектеулер:\n",
    "$$ y_i - (\\langle w, x_i \\rangle + b) \\le ε + \\xi_i \\quad (\\text{дәлізден жоғары нүктелер үшін}) $$\n",
    "$$ (\\langle w, x_i \\rangle + b) - y_i \\le ε + \\xi_i^* \\quad (\\text{дәлізден төмен нүктелер үшін}) $$\n",
    "$$ \\xi_i, \\xi_i^* \\ge 0 $$\n",
    "\n",
    "* $ε$ (эпсилон) — сызықтан бір жаққа қарай \"сезімтал емес аймақтың\" ені.  \n",
    "* $\\xi_i$ және $\\xi_i^*$ — $x_i$ нүктесінің дәлізден жоғары немесе төмен **қаншалықты** \"шығып кеткенін\" өлшейтін әлсіз айнымалылар.  \n",
    "* `C` — модельдің \"тегістігі\" мен қателер саны арасындағы тепе-теңдікті бақылайтын реттеу параметрі.\n",
    "\n",
    "#### Екі жақты (дуальды) форма және SVR-дегі тірек векторлардың рөлі\n",
    "\n",
    "Классификациядағы сияқты, практикалық есептеулер (және ядроларды пайдалану) үшін \"екі жақты\" форма қолданылады. Болжауға арналған қорытынды формула келесідей:\n",
    "\n",
    "$$ \\text{болжау}(x) = \\left( \\sum_{i \\in SV} (\\alpha_i - \\alpha_i^*) K(x_i, x) \\right) + b $$\n",
    "\n",
    "**Осы негізгі формуланы талдап көрейік:**\n",
    "* **$K(x_i, x)$** — бұл жаңа $x$ нысанының $x_i$ тірек векторына \"ұқсастығын\" өлшейтін ядро.  \n",
    "* **$SV$** — бұл **тірек векторлар** жиыны, яғни тек $ε$-дәлізінің шекарасында немесе оның сыртында жатқан нүктелер.  \n",
    "* **$\\alpha_i$ және $\\alpha_i^*$** — бұл **Лагранж көбейткіштері**, оларды интуитивті түрде тірек векторлардың регрессия сызығын өздеріне \"тартатын\" \"күштері\" ретінде елестетуге болады.  \n",
    "  * **$\\alpha_i > 0$** (және $\\alpha_i^*=0$) дәлізден **жоғары** орналасқан нүктелер үшін. Олар сызықты **жоғары қарай** тартады.  \n",
    "  * **$\\alpha_i^* > 0$** (және $\\alpha_i=0$) дәлізден **төмен** орналасқан нүктелер үшін. Олар сызықты **төмен қарай** тартады.  \n",
    "  * Дәліздің **ішіндегі** барлық нүктелер үшін $\\alpha_i=0$ және $\\alpha_i^*=0$. Олар қорытынды модельге **әсер етпейді**.  \n",
    "* **$(\\alpha_i - \\alpha_i^*)$** өрнегі — бұл $i$-ші тірек вектордың модельдегі қорытынды **\"салмағы\"**. Егер нүкте жоғары тартса, ол оң, ал төмен тартса, теріс болады.\n",
    "\n",
    "**Қарапайым сөзбен:** қорытынды регрессиялық қисық жаңа нысанның барлық бұзушы-нүктелермен (тірек векторлармен) \"ұқсастықтарының\" салмақталған қосындысы ретінде құрылады.\n",
    "\n",
    "#### Scikit-Learn-де іске асыру\n",
    "\n",
    "`scikit-learn`-де тірек векторлар әдісімен регрессия жасауға арналған бірнеше класс бар:\n",
    "\n",
    "1. **`sklearn.svm.SVR`**  \n",
    "   * Ядролардың барлық түрлерін (`linear`, `poly`, `rbf`) қолдайтын ең әмбебап іске асыру.  \n",
    "   * **Негізгі гиперпараметрлер:**  \n",
    "     * `kernel`: Ядро түрі. Әдепкі бойынша `'rbf'`.  \n",
    "     * `C`: Реттеу параметрі.  \n",
    "     * `gamma`: `rbf` және `poly` ядролары үшін коэффициент.  \n",
    "     * `epsilon`: $ε$-дәлізінің ені.  \n",
    "\n",
    "2. **`sklearn.svm.LinearSVR`**  \n",
    "   * **Тек сызықтық ядро үшін** мамандандырылған және жылдам іске асыру.  \n",
    "   * Үлкен деректерде `SVR(kernel='linear')`-ге қарағанда әлдеқайда жылдам.  \n",
    "   * **Қашан қолдану керек:** Деректердегі тәуелділік сызықтық болғанда және жылдамдық маңызды болғанда.  \n",
    "\n",
    "3. **`sklearn.svm.NuSVR`**  \n",
    "   * `C`-ның орнына `nu` параметрін қолданатын баламалы іске асыру.  \n",
    "   * `nu` (0-ден 1-ге дейін) тірек векторлардың үлесін бақылайды.  \n",
    "\n",
    "**`SVR` мен `LinearSVR`-дің негізгі айырмашылығы** — `SVR` ядролардың арқасында сызықтық емес модельдер құруға мүмкіндік береді, ал `LinearSVR` тек сызықтық есептер үшін оңтайландырылған.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-бөлім: Модельді бағдарламалау схемасы (Workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таңдалған алгоритмге (KNN, SVM немесе басқа) қарамастан, оны кодта қолдану процесі стандартты схема бойынша жүреді. Бұл үшін біз қуатты Python кітапханаларын қолданамыз: `pandas` деректермен жұмыс істеу үшін, `matplotlib` және `seaborn` визуализация үшін, және `scikit-learn` машиналық оқыту үшін."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-қадам: Деректерді жүктеу және дайындау\n",
    "*   **Не істейміз:** Деректерді жүктейміз (мысалы, CSV-ден) және барлау талдауын (EDA) жүргіземіз.\n",
    "*   **Кітапханалар:** `import pandas as pd`, `import seaborn as sns`\n",
    "*   **Мысал:** `df = pd.read_csv('data.csv')`, `sns.countplot(x=df['target'])`\n",
    "\n",
    "#### 2-қадам: Белгілерді (X) және мақсатты (y) анықтау\n",
    "*   **Не істейміз:** Датафреймді `X` белгілер матрицасына және `y` мақсатты айнымалы векторына бөлеміз.\n",
    "*   **Мысал:** `X = df.drop('target', axis=1)`, `y = df['target']`\n",
    "\n",
    "#### 3-қадам: Оқыту және тест жиынтықтарына бөлу\n",
    "*   **Не істейміз:** Модель оқытылмайтын деректердің бір бөлігін оның сапасын әділ бағалау үшін бөліп аламыз.\n",
    "*   **Кітапханалар:** `from sklearn.model_selection import train_test_split`\n",
    "*   **Мысал:** `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)`\n",
    "\n",
    "#### 4-қадам: Белгілерді масштабтау\n",
    "*   **Не істейміз:** Барлық белгілерді бірыңғай масштабқа келтіреміз. **KNN және SVM үшін өте маңызды!**\n",
    "*   **Кітапханалар:** `from sklearn.preprocessing import StandardScaler`\n",
    "*   **Мысал:** `scaler = StandardScaler()`, `X_train_scaled = scaler.fit_transform(X_train)`, `X_test_scaled = scaler.transform(X_test)`\n",
    "*   **Маңызды:** `fit` әдісі (орташа және стандартты ауытқуды есептеу) тесттен ақпараттың ағып кетуін болдырмау үшін **тек оқыту деректерінде** шақырылады!\n",
    "\n",
    "#### 5-қадам: Модельді құру және оқыту\n",
    "*   **Не істейміз:** Модель данасын құрып, оны масштабталған оқыту деректерінде оқытамыз.\n",
    "*   **Кітапханалар:** `from sklearn.neighbors import KNeighborsClassifier`, `from sklearn.svm import SVC`\n",
    "*   **Мысал:** `model = SVC(C=1.0, kernel='rbf')`, `model.fit(X_train_scaled, y_train)`\n",
    "\n",
    "#### 6-қадам: Болжау және сапаны бағалау\n",
    "*   **Не істейміз:** Тест деректерінде болжамдар жасаймыз және оларды нақты мәндермен салыстырамыз.\n",
    "*   **Кітапханалар:** `from sklearn.metrics import classification_report, confusion_matrix`\n",
    "*   **Мысал:** `predictions = model.predict(X_test_scaled)`, `print(classification_report(y_test, predictions))`\n",
    "\n",
    "#### Оңтайландыру: Pipeline және GridSearchCV\n",
    "4-6 қадамдарды автоматтандыру және ең жақсы гиперпараметрлерді табу үшін `Pipeline` (қадамдарды конвейерге біріктіреді) және `GridSearchCV` (параметрлерді тор бойынша тексереді) қолданылады."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-бөлім: Python-дағы практикалық мысалдар"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Барлық қажетті кітапханаларды импорттаймыз\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Жақсырақ визуализация үшін баптаулар\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-мысал: Бинарлық классификация (Шараптың жалғандығы)\n",
    "\n",
    "**Мәселе:** Химиялық талдау негізінде шараптың нағыз (`Legit`) немесе жалған (`Fraud`) екенін анықтау."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Деректерді жүктейміз\n",
    "df_fraud = pd.read_csv('https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/data/wine_fraud.csv')\n",
    "\n",
    "# EDA\n",
    "print('Деректер жинағы туралы ақпарат:')\n",
    "df_fraud.info()\n",
    "print('\\nКластардың балансы:')\n",
    "print(df_fraud['quality'].value_counts())\n",
    "sns.countplot(x='quality', data=df_fraud)\n",
    "plt.title('Шарап туралы деректер жинағындағы кластардың балансы')\n",
    "plt.show()\n",
    "\n",
    "# Деректерді дайындау\n",
    "X = df_fraud.drop('quality', axis=1)\n",
    "# Ыңғайлылық үшін 'Legit'/'Fraud' мәндерін 0/1-ге айналдырамыз\n",
    "y = df_fraud['quality'].map({'Legit': 0, 'Fraud': 1})\n",
    "\n",
    "# 'type' категориялық белгісін өңдеу\n",
    "X = pd.get_dummies(X, columns=['type'], drop_first=True)\n",
    "\n",
    "# Деректерді бөлу\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Бинарлық классификацияға арналған KNN моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline жасаймыз: алдымен масштабтау, содан кейін KNN моделі\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Іріктеуге арналған параметрлер торын белгілейміз: ең жақсы k-ны іздейміз\n",
    "k_values = list(range(1, 20))\n",
    "param_grid_knn = {'knn__n_neighbors': k_values}\n",
    "\n",
    "# GridSearchCV құрып, оқытамыз\n",
    "grid_knn = GridSearchCV(knn_pipe, param_grid_knn, cv=5, scoring='accuracy')\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"KNN үшін ең жақсы параметр: {grid_knn.best_params_}\")\n",
    "\n",
    "# KNN моделін бағалау\n",
    "knn_preds = grid_knn.predict(X_test)\n",
    "print(\"\\n--- KNN моделінің сапасы бойынша есеп ---\")\n",
    "print(classification_report(y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    " \n",
    "cm = confusion_matrix(y_test, knn_preds)\n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legit', 'Fraud'], yticklabels=['Legit', 'Fraud'])\n",
    "plt.xlabel('Болжанған класс')\n",
    "plt.ylabel('Нақты класс')\n",
    "plt.title('KNN моделі үшін қателіктер матрицасы')\n",
    "plt.savefig(\"confusion_matrix_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Бинарлық классификацияға арналған SVM моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM үшін Pipeline жасаймыз\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    # class_weight='balanced' көмегімен кластардың теңгерімсіздігін ескереміз\n",
    "    ('svm', SVC(class_weight='balanced'))\n",
    "])\n",
    "\n",
    "# SVM үшін параметрлер торы. C және gamma - RBF ядросының негізгі параметрлері\n",
    "param_grid_svm = {\n",
    "    'svm__C': [0.1, 1, 10],\n",
    "    'svm__gamma': ['scale', 'auto', 0.1]\n",
    "}\n",
    "\n",
    "# GridSearchCV құрып, оқытамыз\n",
    "grid_svm = GridSearchCV(svm_pipe, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "print(f\"SVM үшін ең жақсы параметрлер: {grid_svm.best_params_}\")\n",
    "\n",
    "# SVM моделін бағалау\n",
    "svm_preds = grid_svm.predict(X_test)\n",
    "print(\"\\n--- SVM моделінің сапасы бойынша есеп ---\")\n",
    "print(classification_report(y_test, svm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    " \n",
    "cm = confusion_matrix(y_test, svm_preds)\n",
    " \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Legit', 'Fraud'], yticklabels=['Legit', 'Fraud'])\n",
    "plt.xlabel('Болжанған класс')\n",
    "plt.ylabel('Нақты класс')\n",
    "plt.title('SVM моделі үшін қателіктер матрицасы')\n",
    "plt.savefig(\"confusion_matrix_heatmap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Бинарлық классификация есебінде KNN мен SVM-ді салыстыру\n",
    "\n",
    "**Қорытындылар:**\n",
    "1.  **Метрикалар:** `classification_report` есептерін салыстырыңыз. Қай модель `Fraud` класы (белгі 1) үшін жоғарырақ `f1-score` береді? Алаяқтықты немесе ақауларды іздеу есептерінде көбінесе **толықтық (recall)** маңыздырақ, яғни жалған оң нәтижелердің есебінен болса да, алаяқтық жағдайларын мүмкіндігінше көбірек табу.\n",
    "2.  **Өнімділік:** Бұл деректер жинағында SVM жақсырақ нәтиже көрсетуі ықтимал. Максималды аралықпен күрделі шекара құру қабілетінің арқасында ол кластарды тиімдірек бөледі.\n",
    "3.  **Күрделілік:** SVM-ді баптау гиперпараметрлердің көптігіне (`C`, `gamma`, ядро түрі) байланысты қиынырақ, бірақ `GridSearchCV` бұл процесті автоматтандырады."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-мысал: Көп класты классификация (Шарап сорттары)\n",
    "\n",
    "**Мәселе:** 13 химиялық белгі негізінде шарапты үш сорттың біріне жіктеу.\n",
    "\n",
    "#### Алгоритмдер көп класты есепті қалай шешеді?\n",
    "-   **KNN:** Табиғи түрде. Ол жай ғана K ең жақын көршіні тауып, 3+ кластың қайсысы басым екенін қарайды.\n",
    "-   **SVM:** SVM табиғаты бойынша бинарлық классификатор болып табылады. Көп класты есепті шешу үшін ол стратегиялардың бірін қолданады:\n",
    "    -   **One-vs-Rest (OvR):** N классификатор оқытылады, мұндағы N — кластар саны. Әр классификатор \"өз\" класын қалғандарынан (`Rest`) ажыратуды үйренеді.\n",
    "    -   **One-vs-One (OvO):** Әрбір мүмкін класс жұбы үшін N * (N-1) / 2 классификатор оқытылады. Жаңа нысан көптеген \"жекпе-жектерде\" \"жеңген\" класспен жіктеледі. **Scikit-learn бұл стратегияны `SVC` үшін әдепкі бойынша қолданады**, себебі ол жиі тиімдірек болады.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn-нен деректерді жүктеу\n",
    "wine_data = load_wine()\n",
    "X = pd.DataFrame(wine_data.data, columns=wine_data.feature_names)\n",
    "y = pd.Series(wine_data.target)\n",
    "\n",
    "# EDA\n",
    "print(\"Шарап сорттары деректер жинағының өлшемдері:\", X.shape)\n",
    "print(\"\\nКластардың балансы:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Деректерді бөлу\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Көп класты классификацияға арналған KNN моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бұрынғыдай Pipeline қолданамыз\n",
    "grid_knn_multi = GridSearchCV(knn_pipe, param_grid_knn, cv=5, scoring='accuracy')\n",
    "grid_knn_multi.fit(X_train, y_train)\n",
    "\n",
    "print(f\"KNN үшін ең жақсы параметр: {grid_knn_multi.best_params_}\")\n",
    "\n",
    "# Бағалау\n",
    "knn_preds_multi = grid_knn_multi.predict(X_test)\n",
    "print(\"\\n--- KNN моделінің сапасы бойынша есеп (көп класты) ---\")\n",
    "print(classification_report(y_test, knn_preds_multi))\n",
    "\n",
    "print(\"Қателіктер матрицасы:\")\n",
    "print(confusion_matrix(y_test, knn_preds_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Көп класты классификацияға арналған SVM моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластар теңгерімді болғандықтан, SVM үшін class_weight-сіз Pipeline\n",
    "svm_pipe_multi = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "param_grid_svm_multi = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': ['scale', 'auto', 0.1, 0.01]\n",
    "}\n",
    "\n",
    "grid_svm_multi = GridSearchCV(svm_pipe_multi, param_grid_svm_multi, cv=5, scoring='accuracy')\n",
    "grid_svm_multi.fit(X_train, y_train)\n",
    "\n",
    "print(f\"SVM үшін ең жақсы параметрлер: {grid_svm_multi.best_params_}\")\n",
    "\n",
    "svm_preds_multi = grid_svm_multi.predict(X_test)\n",
    "print(\"\\n--- SVM моделінің сапасы бойынша есеп (көп класты) ---\")\n",
    "print(classification_report(y_test, svm_preds_multi))\n",
    "\n",
    "print(\"Қателіктер матрицасы:\")\n",
    "print(confusion_matrix(y_test, svm_preds_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Көп класты классификация есебінде салыстыру\n",
    "\n",
    "**Қорытындылар:**\n",
    "1.  **Метрикаларды түсіндіру:** Есепте енді үш кластың (0, 1, 2) әрқайсысы үшін жолдар және орташаланған мәндер (`macro avg`, `weighted avg`) бар.\n",
    "2.  **Қателіктер матрицасы:** Енді бұл 3x3 матрица. `i` жолы мен `j` бағанының қиылысындағы элемент нақты `i` класындағы нысандардың қаншасы `j` класы ретінде болжанғанын көрсетеді. Диагональдық элементтер — дұрыс жіктелген нысандар. Диагональдан тыс элементтер — қателер. Бұл матрицаны талдау модельдің қай кластарды бір-бірімен шатастыратынын түсінуге көмектеседі.\n",
    "3.  **Нәтиже:** Бұл классикалық деректер жинағында екі модель де өте жоғары, 100% дәлдікке жақын нәтижелер көрсетуі ықтимал, бірақ дұрыс таңдалған параметрлері бар SVM жиі сәл дәлірек болады."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Қорытынды\n",
    "\n",
    "Біз табиғаты бойынша өте әртүрлі, бірақ қуатты екі классификация алгоритмін қарастырдық.\n",
    "\n",
    "| Сипаттама | K-ең жақын көршілер (KNN) | Тірек векторлар әдісі (SVM) |\n",
    "| :--- | :--- | :--- |\n",
    "| **Негізгі идея** | Көршілердің көпшілік дауысы бойынша жіктеу | Оңтайлы бөлуші гипержазықтықты іздеу |\n",
    "| **Модель түрі** | Метрикалық, \"жалқау\" (модель құрмайды) | Геометриялық, нақты модель құрады |\n",
    "| **Негізгі параметрлер** | `n_neighbors` (көршілер саны) | `C` (реттеу), `kernel`, `gamma` (RBF үшін) |\n",
    "| **Талаптар** | Деректерді **міндетті** түрде масштабтау | Деректерді **міндетті** түрде масштабтау |\n",
    "| **Ең жақсы сәйкес келеді** | Жылдам прототиптерге, деректер \"таза\" және жақсы топтастырылған кезде | Сызықтық емес шекаралары бар күрделі есептерге, жоғары өлшемді кеңістіктерде |\n",
    "| **Түсіндірілуі** | Жоғары (көршілерге қарауға болады) | Төмен (әсіресе сызықтық емес ядролармен) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
