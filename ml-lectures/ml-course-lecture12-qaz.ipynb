{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12-дәріс: Кластерлеу. Мұғалімсіз оқыту арқылы деректердегі құрылымды іздеу\n",
    "\n",
    "**Дәрістің мақсаты:**\n",
    "1. Мұғаліммен оқыту мен **мұғалімсіз оқыту** арасындағы айырмашылықты түсіну.\n",
    "2. Центроидтарға негізделген ең танымал кластерлеу алгоритмі - **K-Means**-ті зерттеу.\n",
    "3. **Иерархиялық кластерлеумен** және дендрограммалармен қысқаша танысу.\n",
    "4. Тығыздыққа негізделген кластерлеу алгоритмі - **DBSCAN**-ді зерттеу.\n",
    "5. Қай алгоритмнің қай есепке жақсырақ сәйкес келетінін түсіну үшін тәсілдерді салыстыру."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-бөлім: Мұғалімсіз оқытуға кіріспе\n",
    "\n",
    "Осы уақытқа дейін біз **мұғаліммен оқыту (Supervised Learning)** парадигмасында жұмыс істедік. Бізде әрқашан `X` белгілері мен `y` дұрыс жауаптары бар таңбаланған оқыту таңдамасы болды. Біздің мақсатымыз — `X` бойынша `y`-ті болжайтын модель құру еді.\n",
    "\n",
    "Енді біз **мұғалімсіз оқытуға (Unsupervised Learning)** көшеміз. Басты айырмашылық — бізде **тек `X` белгілері бар**, ал **`y` дұрыс жауаптары жоқ**. Міндет — белгіні болжау емес, деректердің өзіндегі жасырын құрылымды, заңдылықтарды немесе топтарды табу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Мұғалімсіз оқыту есептерінің түрлері\n",
    "\n",
    "Мұғалімсіз оқыту — бұл тұтас бір алгоритмдер тобы. Кластерлеу — оның ең танымал, бірақ жалғыз өкілі емес.\n",
    "\n",
    "1.  **Кластерлеу (Clustering):**\n",
    "    *   **Мақсаты:** Ұқсас объектілерді бірге топтастыру, ал ұқсас еместерін әртүрлі топтарға (кластерлерге) бөлу.\n",
    "    *   **Мысал:** Дүкен клиенттерін олардың сатып алу мінез-құлқы бойынша сегменттеу.\n",
    "    *   **Алгоритмдер:** K-Means, DBSCAN, Иерархиялық кластерлеу.\n",
    "\n",
    "2.  **Өлшемділікті азайту (Dimensionality Reduction):**\n",
    "    *   **Мақсаты:** Деректер жинағындағы белгілер санын азайту, бірақ сонымен бірге мүмкіндігінше көп пайдалы ақпаратты сақтау. Бұл \"өлшемділік қарғысымен\" күресуге, басқа модельдердің оқуын жылдамдатуға және деректерді визуализациялауға көмектеседі.\n",
    "    *   **Мысал:** 50 белгісі бар деректер жинағын 2D-графикте сызу үшін 2 белгіге түрлендіру.\n",
    "    *   **Алгоритмдер:** Негізгі компоненттер әдісі (PCA), t-SNE.\n",
    "\n",
    "3.  **Ассоциативті ережелерді іздеу (Association Rule Learning):**\n",
    "    *   **Мақсаты:** Үлкен деректер жинақтарындағы айнымалылар арасындағы қызықты өзара байланыстар мен заңдылықтарды табу.\n",
    "    *   **Мысал:** Супермаркеттегі чектерді талдау арқылы \"Егер сатып алушы {Нан, Сүт} сатып алса, онда ол жоғары ықтималдылықпен {Май} да сатып алады\" сияқты ережелерді табу.\n",
    "    *   **Алгоритмдер:** Apriori, Eclat.\n",
    "\n",
    "Бұл дәрісте біз **кластерлеуге** назар аударамыз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-бөлім: K-Means алгоритмі (Центроидтарға негізделген кластерлеу)\n",
    "\n",
    "K-Means — ең ескі және ең танымал кластерлеу алгоритмдерінің бірі. Оның идеясы өте қарапайым: деректер топтасатын `K` орталықты (центроидты) табу.\n",
    "\n",
    "#### Интуициясы: Ллойд алгоритмі\n",
    "Алгоритм итеративті түрде жұмыс істейді:\n",
    "1.  **0-қадам: `K`-ны таңдау** — кластерлер санын анықтау.\n",
    "2.  **1-қадам: Инициализация.** `K` центроидты кездейсоқ орналастыру.\n",
    "3.  **2-қадам: Тағайындау.** Әрбір нүктені ең жақын центроидқа жатқызу.\n",
    "4.  **3-қадам: Жаңарту.** Әрбір центроидтың орнын оның кластеріндегі барлық нүктелердің орташа мәні ретінде қайта есептеу.\n",
    "5.  **Қайталау:** 2 және 3-қадамдарды жинақталғанша (өзгеріс тоқтағанша) қайталау.\n",
    "\n",
    "> **Интерактивті визуализация:** K-Means алгоритмімен тікелей жұмыс істеп көруге болады: \n",
    "> [https://www.naftaliharris.com/blog/visualizing-k-means-clustering/](https://www.naftaliharris.com/blog/visualizing-k-means-clustering/)\n",
    "\n",
    "Математикалық тұрғыдан, K-Means `inertia` деп те аталатын **кластерішілік қашықтықтардың квадраттарының қосындысын (Within-Cluster Sum of Squares - WCSS)** минимизациялауға тырысады:\n",
    "$$ \\Phi_0 = \\sum_{a=1}^{K} \\sum_{i: a_i=a} ||x_i - \\mu_a||^2 \\rightarrow \\min $$\n",
    "мұндағы $\\mu_a$ — бұл $a$ кластерінің центроиды."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means Scikit-Learn-де\n",
    "\n",
    "*   **Класс:** `sklearn.cluster.KMeans`\n",
    "*   **Негізгі гиперпараметрлер:**\n",
    "    *   `n_clusters`: Сол `K`, яғни кластерлер саны. **Ең маңызды параметр.**\n",
    "    *   `init`: Центроидтарды инициализациялау әдісі.\n",
    "        *   `'random'`: Деректер жинағынан `K` кездейсоқ нүктені бастапқы центроидтар ретінде таңдайды. Бұл әдіс өте жылдам, бірақ егер бастапқы центрлер бір-біріне жақын болып қалса, сәтсіз жинақталуға әкелуі мүмкін.\n",
    "        *   `'k-means++'` (әдепкі бойынша): Бұл \"ақылды\" инициализация әдісі. Ол былай жұмыс істейді:\n",
    "            1.  Бірінші центроид кездейсоқ таңдалады.\n",
    "            2.  Әрбір келесі центроид қалған нүктелердің ішінен, таңдалып қойылған центроидтардың ең жақынына дейінгі **қашықтықтың квадратына** пропорционалды ықтималдықпен таңдалады.\n",
    "            **Қарапайым сөзбен:** `k-means++` бастапқы центроидтарды мүмкіндігінше **бір-бірінен алыс** орналастыруға тырысады. Бұл алгоритмнің жылдам және сапалы жинақталу мүмкіндігін едәуір арттырады.\n",
    "    *   `n_init`: Алгоритм әртүрлі кездейсоқ бастапқы центроидтармен қанша рет іске қосылатыны. Модель барлық іске қосулардың ішіндегі ең жақсы нәтижені (ең аз `inertia_` мәнімен) қайтарады.\n",
    "        *   **`'auto'` (1.4 нұсқасынан бастап әдепкі бойынша):** Бұл ақылды баптау. Егер `init='k-means++'` болса, онда тек **бір** рет іске қосылады (себебі бұл әдіс детерминирленген). Егер `init='random'` болса, онда **10** рет іске қосылады. Бұл әдепкі мән көп жағдайда тамаша таңдау болып табылады.\n",
    "    *   `random_state`: Кездейсоқ сандар генераторын инициализациялауға арналған сан. Нәтижелердің қайталануын қамтамасыз ету үшін қолданылады, себебі `k-means++` және `'random'` әдістерінде кездейсоқтық элементі бар."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `K`-ны қалай таңдауға болады? Шынтақ әдісі (Elbow Method)\n",
    "\n",
    "K-Means-тің басты кемшілігі — біз `K`-ны алдын ала көрсетуіміз керек. **Шынтақ әдісі** — оны табуға арналған танымал эвристика:\n",
    "1.  Біз K-Means-ті әртүрлі кластерлер саны үшін іске қосамыз (мысалы, `K=2`-ден `10`-ға дейін).\n",
    "2.  Әрбір `K` үшін біз соңғы `WCSS` мәнін есептейміз (`model.inertia_` атрибуты).\n",
    "3.  `WCSS`-тің `K`-ға тәуелділік графигін саламыз.\n",
    "4.  Графиктен \"шынтаққа\" ұқсас нүктені іздейміз — қисықтың жазықтала бастайтын жері. Дәл осы оңтайлы `K`-ға кандидат болып табылады."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Әртүрлі кітапханаларды қамту үшін бірнеше орта айнымалыларын орнатамыз\n",
    "# Осы операция үшін проблемалы параллелизмді кепілді түрде өшіру үшін '1' мәнін орнатамыз\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'\n",
    "\n",
    "# Енді қалғандарын импорттаймыз\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Деректерді генерациялаймыз\n",
    "X, y = make_blobs(n_samples=500, centers=4, random_state=42, cluster_std=1.0)\n",
    "\n",
    "ssd = []\n",
    "k_range = range(1, 11)\n",
    "for k in k_range:\n",
    "    model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    model.fit(X)\n",
    "    ssd.append(model.inertia_)\n",
    "\n",
    "# График сызамыз\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(k_range, ssd, 'o-')\n",
    "plt.xlabel(\"Кластерлер саны (K)\")\n",
    "plt.ylabel(\"Квадраттық қашықтықтар қосындысы (WCSS)\")\n",
    "plt.title(\"K-Means үшін шынтақ әдісі\")\n",
    "plt.xticks(k_range)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оңтайлы K мәнімен нәтижені визуализациялау\n",
    "\n",
    "\"Шынтақ әдісі\" графигінен біз кластерлердің оңтайлы саны K=4 екенін көреміз.\n",
    "Енді осы мәнмен соңғы модельді оқытып, нәтижесін көрейік."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. K=4 мәнімен соңғы модельді оқытамыз\n",
    "final_model = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "labels = final_model.fit_predict(X)\n",
    "\n",
    "# Кластер белгілері — бұл әр нүктеге кластер нөмірі (0-ден 3-ке дейін) тағайындалған массив\n",
    "print(\"Алғашқы 10 нүкте үшін кластер белгілерінің мысалдары:\")\n",
    "print(labels[:10])\n",
    "\n",
    "# 2. Кластерлерді визуализациялаймыз\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Нүктелерді кластер белгілеріне сәйкес бояп, сызамыз\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=labels, palette='viridis', s=60)\n",
    "\n",
    "# Кластер центрлерін жақсы көрінуі үшін бөлек сызамыз\n",
    "centers = final_model.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.8, marker='X', label='Центроидтар')\n",
    "\n",
    "plt.title(\"K-Means кластерлеу нәтижесі (K=4)\")\n",
    "plt.xlabel(\"Белгі 1\")\n",
    "plt.ylabel(\"Белгі 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "# Алдымен байланыс матрицасын (linkage matrix) есептеу керек\n",
    "linked = linkage(X, method='ward')\n",
    "\n",
    "# Енді дендрограмманы саламыз\n",
    "plt.figure(figsize=(12, 8))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "plt.title('Иерархиялық кластерлеу дендрограммасы')\n",
    "plt.ylabel('Уорд бойынша қашықтық')\n",
    "\n",
    "# K таңдау үшін кесу сызығын қосамыз\n",
    "plt.axhline(y=35, c='k', linestyle='--') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ең ұзын тік кесінділерді көретін жерде көлденең сызық жүргізіп, біз 4 сызықты қиып өтеміз, бұл да 4 кластердің бар екенін көрсетеді. Бұл - иерархиялық кластерлеу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-бөлім: Баламалы тәсіл — Иерархиялық кластерлеу\n",
    "\n",
    "K-Means-тен басқа, қашықтыққа негізделген тағы бір танымал әдіс бар — **иерархиялық кластерлеу**. Оның басты ерекшелігі — ол деректерді жай ғана `K` кластерге бөлмейді, керісінше бір-біріне салынған кластерлердің тұтас \\\"ағашын\\\" құрады.\n",
    "\n",
    "#### Интуициясы: Агломеративті тәсіл\n",
    "\n",
    "Иерархиялық кластерлеудің ең көп таралған түрі — **агломеративті** (біріктіруші). Алгоритм \"төменнен жоғарыға\" қарай жұмыс істейді:\n",
    "1.  **Бастамасы:** Әрбір дерек нүктесі жеке кластер болып саналады.\n",
    "2.  **1-қадам:** Бір-біріне **ең жақын** екі кластер табылып, бір кластерге біріктіріледі.\n",
    "3.  **2-қадам:** Қайтадан ең жақын екі кластер табылып, біріктіріледі.\n",
    "4.  **Қайталау:** Процесс барлық нүктелер бір үлкен кластерге біріккенше қайталанады.\n",
    "\n",
    "#### Иерархиялық кластерлеу Scikit-Learn және SciPy-да\n",
    "*   **Класс:** `sklearn.cluster.AgglomerativeClustering`\n",
    "*   **Негізгі гиперпараметрлер:**\n",
    "    *   `n_clusters`: Нәтижесінде алғымыз келетін кластерлер саны (егер `distance_threshold=None` болса).\n",
    "    *   `metric` (немесе `affinity`): Нүктелер арасындағы қашықтық метрикасы (`euclidean`, `manhattan`).\n",
    "    *   `linkage`: **Ең маңызды параметр.** **Кластерлер арасындағы** қашықтықты өлшеу ережесі.\n",
    "\n",
    "#### Әртүрлі `linkage` әдістері қалай жұмыс істейді?\n",
    "\n",
    "Бізде екі кластер, $U$ және $V$ бар деп есептейік, және біз олардың арасындағы қашықтықты, $D(U, V)$, өлшегіміз келеді.\n",
    "\n",
    "![linkage](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/linkage.png)\n",
    "\n",
    "*   **`'single'` (Жақын көрші қашықтығы):**\n",
    "    *   **Интуициясы:** Кластерлер арасындағы қашықтық — осы кластерлердегі **ең жақын екі** нүктенің арасындағы қашықтық. Бұл созылған, таспа тәрізді кластерлерді жақсы табатын \"оптимистік\" тәсіл.\n",
    "    $$ D(U, V) = \\min_{u \\in U, v \\in V} d(u, v) $$\n",
    "\n",
    "*   **`'complete'` (Алыс көрші қашықтығы):**\n",
    "    *   **Интуициясы:** Кластерлер арасындағы қашықтық — осы кластерлердегі **ең алыс екі** нүктенің арасындағы қашықтық. Бұл \"пессимистік\" тәсіл ықшам, шар тәрізді кластерлер құруға бейім.\n",
    "    $$ D(U, V) = \\max_{u \\in U, v \\in V} d(u, v) $$\n",
    "\n",
    "*   **`'average'` (Топтық орташа қашықтық):**\n",
    "    *   **Интуициясы:** Қашықтық — бір кластердегі нүктелер мен екінші кластердегі нүктелер арасындағы барлық мүмкін жұптық қашықтықтардың **арифметикалық ортасы**. Бұл `single` мен `complete` арасындағы ымыра.\n",
    "    $$ D(U, V) = \\frac{1}{|U| \\cdot |V|} \\sum_{u \\in U} \\sum_{v \\in V} d(u, v) $$\n",
    "\n",
    "*   **`'ward'` (Уорд әдісі):**\n",
    "    *   **Интуициясы:** Бұл әдіс басқаша жұмыс істейді. Ол бірігуі **жалпы кластерішілік дисперсияның (WCSS) минималды артуына** әкелетін екі кластерді біріктіреді. Шын мәнінде, ол әр қадамда барлық мүмкін жаңа кластерлердің ішіндегі ең ықшамын жасайтын бірігуді таңдайды.\n",
    "    *   Бұл әдіс шамамен бірдей өлшемдегі кластерлер құруға бейім және егер сіз сфералық кластерлер табамын деп күтсеңіз, жиі ең жақсы әдепкі таңдау болып табылады.\n",
    "\n",
    "#### Визуализация: Дендрограмма\n",
    "\n",
    "Осы біріктіру процесін `SciPy` кітапханасының көмегімен салуға ең ыңғайлы **дендрограмма** арқылы визуализациялауға болады.\n",
    "\n",
    "**Дендрограмманы қалай оқу керек:**\n",
    "*   **Тігінен** биіктік — бірігу болған қашықтық (таңдалған `linkage` әдісіне сәйкес) көрсетілген. Ұзын тік сызықтар бір-бірінен өте алыс кластерлердің біріккенін білдіреді.\n",
    "*   **Дендрограмма** — оңтайлы `K`-ны таңдаудың тағы бір тәсілі. Біз ең ұзын тік сызықты қиып өтетін жерде көлденең кесу сызығын жүргізе аламыз. Қиылысулар саны ұсынылатын кластерлер саны болады."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Визуализация: Практикалық мысалдағы дендрограмма\n",
    "\n",
    "Иерархиялық кластерлеу мен дендрограмманың қарапайым және көрнекі мысалда қалай жұмыс істейтінін көрейік. 12 адам және екі белгісі бар шағын деректер жинағын құрайық: \"Күніне орташа жұмыс сағаты\" және \"Айлық табыс (мыңмен)\". Интуитивті түрде біз 3 топты көреміз деп күтеміз: кеңсе қызметкерлері, студенттер және фрилансерлер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Көрнекі деректер жинағын құрамыз\n",
    "X = np.array([\n",
    "    # 1-топ: Кеңсе қызметкерлері (көп сағат, орташа табыс)\n",
    "    [8, 150], [9, 160], [8.5, 140], [7.5, 155],\n",
    "    # 2-топ: Студенттер (аз сағат, төмен табыс)\n",
    "    [3, 40], [4, 50], [2.5, 35], [3.5, 45],\n",
    "    # 3-топ: Фрилансерлер (икемді сағат, жоғары табыс)\n",
    "    [5, 200], [6, 210], [4.5, 190], [5.5, 220]\n",
    "])\n",
    "\n",
    "# 1. Бастапқы деректерді визуализациялаймыз\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], s=100)\n",
    "plt.title('Бастапқы деректер: 12 адам')\n",
    "plt.xlabel('Күніне жұмыс сағаты')\n",
    "plt.ylabel('Табыс (мыңмен)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 2. Дендрограмманы саламыз\n",
    "# linkage байланыс матрицасын есептейді, 'ward' біріктіру кезінде дисперсияны минимизациялайды\n",
    "linked = linkage(X, method='ward')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "dendrogram(linked,\n",
    "            orientation='top',\n",
    "            labels=[f\"Нүкте {i}\" for i in range(len(X))], # Нүктелерді белгілейміз\n",
    "            distance_sort='descending',\n",
    "            show_leaf_counts=True)\n",
    "\n",
    "plt.title('Иерархиялық кластерлеу дендрограммасы')\n",
    "plt.ylabel('Уорд бойынша қашықтық')\n",
    "plt.axhline(y=100, c='k', linestyle='--') # Кесу сызығын қосамыз\n",
    "plt.show()\n",
    "\n",
    "# 3. K=3 мәнімен AgglomerativeClustering қолданамыз\n",
    "agg_cluster = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
    "labels = agg_cluster.fit_predict(X)\n",
    "\n",
    "# 4. Кластерлеу нәтижесін визуализациялаймыз\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=labels, palette='viridis', s=100)\n",
    "plt.title('Иерархиялық кластерлеу нәтижесі (K=3)')\n",
    "plt.xlabel('Күніне жұмыс сағаты')\n",
    "plt.ylabel('Табыс (мыңмен)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нәтижелерді интерпретациялау:**\n",
    "\n",
    "1.  **Бастапқы деректер:** Бірінші графикте біз 3 визуалды кластерді анық көреміз.\n",
    "2.  **Дендрограмма:**\n",
    "    *   **Төменгі деңгейлер:** Алгоритм алдымен әрбір топтың ішіндегі ең жақын нүктелерді біріктіреді (мысалы, ұқсас параметрлері бар екі студентті).\n",
    "    *   **Орта деңгейлер:** Содан кейін ол осы шағын ішкі топтарды үш үлкен кластерге біріктіреді. Осы кластерлердің ішіндегі \"көпірлердің\" биіктігі салыстырмалы түрде шағын.\n",
    "    *   **Жоғарғы деңгей:** Осы 3 үлкен кластерді біріктіру үшін алгоритмге өте үлкен қашықтыққа \"секіруге\" тура келеді (ұзын тік сызықтар).\n",
    "3.  **K таңдау:** Ең ұзын тік сызық арқылы көлденең кесу сызығын (`y=100`) жүргізу арқылы біз дәл **3** тармақты қиып өтеміз. Бұл біздің кластерлердің оңтайлы саны — **үш** деген интуициямызды растайды.\n",
    "4.  **Қорытынды кластерлеу:** Соңғы график `n_clusters=3` мәнімен `AgglomerativeClustering` есепті мінсіз орындап, біз күткен топтарды дәл анықтағанын көрсетеді."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-бөлім: K-Means қай жерде сәтсіздікке ұшырайды?\n",
    "\n",
    "K-Means өте тиімді, бірақ оның іргелі шектеуі бар: ол кластерлер **сфералық (дөңес) пішінге** ие және шамамен бірдей өлшемде деп болжайды. Ол күрделі пішіндегі кластерлерде сәтсіздікке ұшырайды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Деректерді генерациялаймыз\n",
    "# \"Жарты айлар\" деректер жинағы\n",
    "X_moons, y_moons = make_moons(n_samples=500, noise=0.1, random_state=42)\n",
    "# \"Сақиналар\" деректер жинағы\n",
    "X_circles, y_circles = make_circles(n_samples=500, factor=0.5, noise=0.05, random_state=42)\n",
    "\n",
    "# Деректерді масштабтаймыз, себебі K-Means қашықтыққа негізделген\n",
    "X_moons_scaled = StandardScaler().fit_transform(X_moons)\n",
    "X_circles_scaled = StandardScaler().fit_transform(X_circles)\n",
    "\n",
    "# 2. Әрбір деректер жинағы үшін K-Means оқытамыз\n",
    "# Екі жағдайда да 2 кластер болуы керек екенін білеміз, сондықтан n_clusters=2\n",
    "kmeans_moons = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "kmeans_circles = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "\n",
    "# Кластер белгілерін аламыз\n",
    "labels_moons = kmeans_moons.fit_predict(X_moons_scaled)\n",
    "labels_circles = kmeans_circles.fit_predict(X_circles_scaled)\n",
    "\n",
    "# 3. Нәтижелерді визуализациялаймыз\n",
    "# Екі графикті қатар орналастыру үшін аймақ құрамыз\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# \"Жарты айлар\" үшін график\n",
    "sns.scatterplot(ax=axes[0], x=X_moons[:,0], y=X_moons[:,1], hue=labels_moons, palette='viridis', s=50)\n",
    "axes[0].set_title('K-Means-тің \\\"жарты айлардағы\\\" сәтсіз нәтижесі')\n",
    "axes[0].set_xlabel('Белгі 1')\n",
    "axes[0].set_ylabel('Белгі 2')\n",
    "\n",
    "\n",
    "# \"Сақиналар\" үшін график\n",
    "sns.scatterplot(ax=axes[1], x=X_circles[:,0], y=X_circles[:,1], hue=labels_circles, palette='viridis', s=50)\n",
    "axes[1].set_title('K-Means-тің \\\"сақиналардағы\\\" сәтсіз нәтижесі')\n",
    "axes[1].set_xlabel('Белгі 1')\n",
    "axes[1].set_ylabel('Белгі 2')\n",
    "\n",
    "\n",
    "plt.suptitle('K-Means шектеулері: сызықты емес пішіндегі кластерлер', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-бөлім: DBSCAN алгоритмі (Тығыздыққа негізделген кластерлеу)\n",
    "\n",
    "DBSCAN мүлдем басқа тәсілді ұсынады. Ол центрлерді іздеудің орнына, **нүктелердің тығыз жиынтығын** іздейді.\n",
    "\n",
    "> **Интерактивті визуализация:** DBSCAN алгоритмімен тікелей жұмыс істеп көруге болады: \n",
    "> [https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/](https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/)\n",
    "\n",
    "#### Негізгі ұғымдар мен гиперпараметрлер\n",
    "DBSCAN екі гиперпараметрмен анықталады:\n",
    "1.  **`eps` (эпсилон):** Көршілес аймақтың радиусы. Бұл біз көршілерді іздейтін қашықтық.\n",
    "2.  **`min_samples`:** Нүктені \"тығыздықтың өзегі\" деп санау үшін `eps`-аймақтағы көршілердің минималды саны (нүктенің өзін қосқанда).\n",
    "\n",
    "#### DBSCAN Scikit-Learn-де\n",
    "*   **Класс:** `sklearn.cluster.DBSCAN`\n",
    "*   **Негізгі гиперпараметрлер:** `eps` және `min_samples`.\n",
    "  \n",
    "Осы параметрлер негізінде барлық нүктелер үш түрге бөлінеді:\n",
    "\n",
    "![dbscan](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/dbscan.png)\n",
    "\n",
    "*   **Core Point (Негізгі нүкте):** `eps`-аймағында кемінде `min_samples` көршісі бар нүкте. Бұл кластердің \"жүрегі\".\n",
    "*   **Border Point (Шекаралық нүкте):** Көршілері `min_samples`-тан аз, бірақ өзі қандай да бір негізгі нүктенің көршісі болып табылатын нүкте. Бұл кластердің \"шеті\".\n",
    "*   **Noise (Шу/Шығарынды):** Негізгі де, шекаралық та емес нүкте. Ол сирек аймақта орналасқан.\n",
    "\n",
    "#### Алгоритмнің қарапайым түсіндірмесі\n",
    "1.  Кездейсоқ, әлі қаралмаған нүкте таңдалады.\n",
    "2.  Егер ол **негізгі** болса, ол **жаңа кластерді** бастайды.\n",
    "3.  Бұл кластер \"өсе\" бастайды: оның барлық көршілері осы кластерге қосылады. Егер көршілердің бірі де негізгі нүкте болса, оның да көршілері қосылады. Процесс кластер өсуін тоқтатқанша жалғасады.\n",
    "4.  Егер нүкте **негізгі болмаса**, ол уақытша \"шу\" деп белгіленеді. Кейінірек ол басқа бір кластердің аймағына түсіп қалса, шекаралық болуы мүмкін.\n",
    "5.  Процесс барлық нүктелер үшін қайталанады."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means нашар, ал DBSCAN жақсы жұмыс істейтін мысал\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X_moons, y_moons = make_moons(n_samples=500, noise=0.1, random_state=42)\n",
    "X_moons_scaled = StandardScaler().fit_transform(X_moons)\n",
    "\n",
    "# Модельдер\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "dbscan = DBSCAN(eps=0.3)\n",
    "\n",
    "# Болжамдар\n",
    "labels_kmeans = kmeans.fit_predict(X_moons_scaled)\n",
    "labels_dbscan = dbscan.fit_predict(X_moons_scaled)\n",
    "\n",
    "# Визуализация\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "sns.scatterplot(ax=axes[0], x=X_moons[:,0], y=X_moons[:,1], hue=labels_kmeans, palette='viridis')\n",
    "axes[0].set_title('K-Means-тің сәтсіз нәтижесі')\n",
    "\n",
    "sns.scatterplot(ax=axes[1], x=X_moons[:,0], y=X_moons[:,1], hue=labels_dbscan, palette='viridis')\n",
    "axes[1].set_title('DBSCAN-ның сәтті нәтижесі')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_circles  # make_moons-ты make_circles-ке ауыстырамыз\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Екі сақина түрінде деректерді генерациялаймыз\n",
    "# factor=0.5 ішкі сақина сыртқысынан екі есе кіші болатынын білдіреді\n",
    "X_circles, y_circles = make_circles(n_samples=500, noise=0.05, factor=0.5, random_state=42)\n",
    "\n",
    "# Деректерді масштабтаймыз, бұл DBSCAN үшін маңызды, себебі eps - қашықтық өлшемі\n",
    "X_circles_scaled = StandardScaler().fit_transform(X_circles)\n",
    "\n",
    "# 2. Модельдерді инициализациялаймыз\n",
    "# K-Means үшін кластерлер 2 болуы керек екенін білеміз\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "# DBSCAN үшін eps-ті таңдаймыз. Ықшам сақиналар үшін ол жарты айларға қарағанда кішірек болуы керек.\n",
    "dbscan = DBSCAN(eps=0.3)\n",
    "\n",
    "# 3. Модельдерді оқытып, кластер белгілерін аламыз\n",
    "labels_kmeans = kmeans.fit_predict(X_circles_scaled)\n",
    "labels_dbscan = dbscan.fit_predict(X_circles_scaled)\n",
    "\n",
    "# 4. Нәтижелерді визуализациялаймыз\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# K-Means үшін график\n",
    "sns.scatterplot(ax=axes[0], x=X_circles[:,0], y=X_circles[:,1], hue=labels_kmeans, palette='viridis')\n",
    "axes[0].set_title('K-Means-тің \\\"сақиналардағы\\\" сәтсіз нәтижесі')\n",
    "axes[0].set_xlabel(\"Белгі 1\")\n",
    "axes[0].set_ylabel(\"Белгі 2\")\n",
    "\n",
    "# DBSCAN үшін график\n",
    "sns.scatterplot(ax=axes[1], x=X_circles[:,0], y=X_circles[:,1], hue=labels_dbscan, palette='viridis')\n",
    "axes[1].set_title('DBSCAN-ның \\\"сақиналардағы\\\" сәтті нәтижесі')\n",
    "axes[1].set_xlabel(\"Белгі 1\")\n",
    "axes[1].set_ylabel(\"Белгі 2\")\n",
    "\n",
    "plt.suptitle('K-Means пен DBSCAN-ды сақина тәрізді деректерде салыстыру', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-бөлім: Кластерлерді интерпретациялау — қарапайым емес міндет\n",
    "\n",
    "Кластерлеу алгоритмдері тек **кластер нөмірлерін** (0, 1, 2, ...) қайтаратынын түсіну маңызды. Олар бұл топтардың **не білдіретінін** айтпайды. Алынған кластерлерге бизнес-мағына беру — **кейінгі өңдеу** немесе **интерпретация** деп аталатын жеке және өте маңызды міндет.\n",
    "\n",
    "**Негізгі тәсіл:**\n",
    "1.  **Белгілерді қосу:** Алынған кластер белгілерін бастапқы, **масштабталмаған** DataFrame-ге қосу.\n",
    "2.  **Кластерлерді профильдеу:** Әрбір кластер ішіндегі белгілердің орташа мәндерін және үлестірімдерін талдау үшін `groupby('cluster').mean()` немесе `.describe()` әдістерін пайдалану.\n",
    "3.  **\"Персоналар\" құру:** Талдау негізінде әрбір кластерге мағыналы атау беру. Мысалы, егер біз интернет-дүкен клиенттерін кластерлесек, бізде мынадай топтар пайда болуы мүмкін:\n",
    "    *   **0-кластер (\"Адал VIP-клиенттер\"):** Жоғары орташа чек, жоғары сатып алу жиілігі, үлкен `total_spent`.\n",
    "    *   **1-кластер (\"Жеңілдік аңшылары\"):** Төмен орташа чек, тек сатылым кезеңіндегі сатып алулар.\n",
    "    *   **2-кластер (\"Жаңадан келгендер\"):** Аз сатып алулар, төмен `total_spent`.\n",
    "\n",
    "Бұл интерпретация математикалық нәтижені **бизнеске пайдалы құралға** айналдыруға мүмкіндік береді."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-бөлім: Дәріс бойынша қорытындылар\n",
    "\n",
    "1.  Біз **Мұғаліммен оқытудан** **Мұғалімсіз оқытуға** көштік, мұндағы басты міндет — белгілі бір белгіні болжау емес, деректердегі **жасырын құрылымды** табу.\n",
    "\n",
    "2.  Біз центроидтар негізінде **сфералық кластерлерді** іздейтін жылдам және қарапайым алгоритм — **K-Means**-ті қарастырдық. Оның басты кемшілігі — **шынтақ әдісі** арқылы бағалауға болатын `K` кластерлер санын алдын ала көрсету қажеттілігі.\n",
    "\n",
    "3.  Біз кластерлер санын анықтауға көмектесетін қуатты визуалды құрал — **Иерархиялық кластерлеу** мен **дендрограммаларға** қысқаша тоқталдық.\n",
    "\n",
    "4.  Біз **тығыздыққа** негізделген **DBSCAN** алгоритмін зерттедік. Ол кластерлер санын алдын ала білуді қажет етпейді, **кез келген пішіндегі** кластерлерді таба алады және **шығарындыларды** автоматты түрде анықтайды.\n",
    "\n",
    "5.  Басты қорытынды: **әмбебап \"ең жақсы\" кластерлеу алгоритмі жоқ**. Әдісті таңдау сіздің деректеріңіздің құрылымына және зерттеу мақсаттарына байланысты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
