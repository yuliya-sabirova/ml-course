{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc0d620f",
   "metadata": {},
   "source": [
    "# 8-дәріс: Белгілер инжинирингі және Логистикалық регрессия\n",
    "\n",
    "**Дәріс мақсаттары:**\n",
    "1. Белгілер инжинирингінің маңыздылығын және негізгі техникаларын түсіну.\n",
    "2. Жетіспейтін деректермен, шығарындылармен және категориялық айнымалылармен жұмыс істеуді үйрену.\n",
    "3. Сызықтық регрессияның классификация есептеріне неліктен сәйкес келмейтінін түсіну.\n",
    "4. Логистикалық регрессияның математикалық негіздерін, соның ішінде логистикалық функцияны, мүмкіндіктерді (odds) және log-odds-ты зерттеу.\n",
    "5. Классификация модельдерінің сапасын бағалаудың негізгі метрикаларын (Confusion Matrix, Accuracy, Precision, Recall, F1, ROC/AUC) меңгеру.\n",
    "6. Логистикалық регрессияны бірнеше класс жағдайына кеңейтуді қарастыру."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d46fa95",
   "metadata": {},
   "source": [
    "## 1-бөлім: Белгілер инжинирингі (Feature Engineering)\n",
    "\n",
    "**Белгілер инжинирингі (Feature Engineering)** — бұл пәндік сала туралы білімді пайдаланып, бар белгілерден жаңа белгілер жасау процесі. Мақсаты — машиналық оқыту алгоритмдері үшін негізгі мәселені ең жақсы сипаттайтын түрде деректерді ұсыну. Модельдің сапасы 80% алгоритмнің күрделілігіне емес, белгілердің сапасына байланысты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e50bd",
   "metadata": {},
   "source": [
    "#### Белгілер инжинирингіндегі үш негізгі тәсіл:\n",
    "\n",
    "1. **Бөліп алу (Extraction):** Күрделі белгілерден жаңа, қарапайым белгілер жасау. Мысалы, толық уақыт белгісінен (`timestamp`) апта күнін, айды немесе тәулік уақытын бөліп алу.\n",
    "2. **Біріктіру (Combination):** Бірнеше белгіні біреуге біріктіру. Мысалы, олардың бірлескен әсерін ескеру үшін полиномиалды белгілерді (`TV_budget * Radio_budget`) жасау.\n",
    "3. **Түрлендіру (Transformation):** Бастапқы белгілердің қасиеттерін жақсарту үшін оларды өзгерту. Бұған масштабтау (`StandardScaler`), логарифмдеу немесе төменде қарастыратын категориялық белгілерді кодтау жатады."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af3c4fe",
   "metadata": {},
   "source": [
    "### 1.1. Жоқ деректермен жұмыс (Missing Data)\n",
    "\n",
    "Нақты деректер ешқашан толық болмайды. Бос орындар деректер жинау қателерінен, жүйелердің істен шығуынан немесе белгілі бір белгінің нысанға қолданылмайтындығынан (мысалы, гаражы жоқ үй үшін 'гараждың салынған жылы') пайда болуы мүмкін."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Бос орындары бар қарапайым DataFrame құрайық\n",
    "data = {'temperature': [25, 26, np.nan, 28, 29, 24],\n",
    "        'humidity': [80, np.nan, 82, 83, 81, 79],\n",
    "        'wind_speed': [10, 12, 11, np.nan, 13, 9]}\n",
    "sample_df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Бос орындары бар бастапқы деректер:\")\n",
    "print(sample_df)\n",
    "\n",
    "print(\"\\n.isNone().sum() көмегімен бос орындарды іздеу:\")\n",
    "print(sample_df.isNone().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc1ce8",
   "metadata": {},
   "source": [
    "#### 1.1.1. Деректерді жою\n",
    "\n",
    "Ең қарапайым тәсіл. Жолдарды (`.dropna(axis=0)`) немесе бүкіл бағандарды (`.dropna(axis=1)`) жоюға болады. Бұл, егер бос орындар өте аз болса ғана ақталған, әйтпесе біз құнды ақпаратты жоғалтуымыз мүмкін."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кез келген бос мәні бар жолдарды жою\n",
    "print(\"Жолдарды жойғаннан кейінгі DataFrame:\")\n",
    "print(sample_df.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa3643",
   "metadata": {},
   "source": [
    "#### 1.1.2. Деректерді толтыру (импутация)\n",
    "\n",
    "Неғұрлым тиімді әдіс. Бос орындарды толтыруға болады:\n",
    "* **Қарапайым мәндермен:** нөлмен, орташа (`.mean()`), медиана (`.median()`) немесе модамен (ең жиі кездесетін мән).\n",
    "* **Жетілдірілген әдістермен:** мысалы, басқа белгілер негізінде бос мәнді болжау арқылы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e384bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бос орындарды баған бойынша орташа мәнмен толтыру\n",
    "print(\"Орташа мәнмен толтырғаннан кейінгі DataFrame:\")\n",
    "print(sample_df.fillna(sample_df.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2362aa17-d00b-4e8a-a01b-f16779c9f873",
   "metadata": {},
   "source": [
    "### 1.2. Дубликаттармен жұмыс (Duplicates)\n",
    "\n",
    "**Дубликаттар** — бұл деректер жинағындағы толығымен бірдей жолдар. Дубликаттардың болуы бірнеше мәселеге әкелуі мүмкін:\n",
    "\n",
    "1. **Нәтижелердің бұрмалануы:** Дубликаттар белгілі бір бақылауларға негізсіз үлкен салмақ береді, бұл статистикалық көрсеткіштерді (орташа, медиана) ығыстырып, модельді оқытуға әсер етуі мүмкін.\n",
    "2. **Деректердің жылыстауы (Data Leakage):** Ең күрделі мәселе. Егер бірдей жол оқыту және тест таңдамаларына түссе, модель тест деректерінде \"тегін\" дұрыс жауап алады. Бұл сапа метрикаларының жасанды түрде жоғарылауына және модельдің шынайы жаңа деректерде қалай жұмыс істейтіні туралы жалған түсінікке әкеледі.\n",
    "\n",
    "Сондықтан деректерді талдаудың кез келген жобасындағы **бірінші қадам** толық дубликаттарды тексеру және жою болуы керек.\n",
    "\n",
    "**Pandas-та олармен қалай жұмыс істеу керек:**\n",
    "* **Анықтау:** `.duplicated().sum()` әдісі толық дубликаттардың санын тез санауға мүмкіндік береді.\n",
    "* **Көру:** Барлық қайталанатын жолдарды (олардың \"түпнұсқаларын\" қоса) көру үшін `df[df.duplicated(keep=False)]` қолданылады.\n",
    "* **Жою:** `.drop_duplicates()` әдісі дубликаттарды жояды, әдепкі бойынша әр жолдың бірінші кездесуін қалдырады."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2858f-71a7-49f9-b861-f82de81c4527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Айқын дубликаттары бар DataFrame құрайық\n",
    "data = {'Аты': ['Арман', 'Айгерім', 'Бауыржан', 'Арман', 'Әлия', 'Айгерім'],\n",
    "        'Жасы': [25, 30, 35, 25, 28, 30],\n",
    "        'Қала': ['Астана', 'Алматы', 'Шымкент', 'Астана', 'Қарағанды', 'Алматы']}\n",
    "df_duplicates = pd.DataFrame(data)\n",
    "\n",
    "print(\"Бастапқы DataFrame:\")\n",
    "print(df_duplicates)\n",
    "\n",
    "# --- Дубликаттарды анықтау ---\n",
    "print(\"\\n--- Анықтау ---\")\n",
    "num_duplicates = df_duplicates.duplicated().sum()\n",
    "print(f\"Деректердегі толық дубликаттар саны: {num_duplicates}\")\n",
    "\n",
    "# Қайталанатын жолдардың өзін көрейік\n",
    "print(\"\\nБарлық қайталанатын жолдарды көрсету (түпнұсқаларды қоса):\")\n",
    "print(df_duplicates[df_duplicates.duplicated(keep=False)])\n",
    "\n",
    "\n",
    "# --- Дубликаттарды жою ---\n",
    "print(\"\\n--- Жою ---\")\n",
    "df_cleaned = df_duplicates.drop_duplicates()\n",
    "print(\"Дубликаттарды жойғаннан кейінгі DataFrame:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "# --- Тексеру ---\n",
    "print(\"\\n--- Тексеру ---\")\n",
    "print(f\"Тазалаудан кейінгі дубликаттар саны: {df_cleaned.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33c8c42",
   "metadata": {},
   "source": [
    "### 1.3. Шығарындылармен жұмыс (Outliers)\n",
    "\n",
    "**Шығарынды** — бұл басқаларынан қатты ерекшеленетін деректер нүктесі. Шығарындылар оқыту нәтижелерін бұрмалап, регрессия сызығын өздеріне \"тартып\" алуы мүмкін."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d12166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Қалыпты таралуды генерациялап, шығарындылар қосайық\n",
    "np.random.seed(42)\n",
    "data_normal = np.random.normal(loc=100, scale=10, size=100)\n",
    "data_with_outliers = np.concatenate([data_normal, [180, 190, -50]]) # 3 шығарынды қосамыз\n",
    "df_outliers = pd.DataFrame(data_with_outliers, columns=['value'])\n",
    "\n",
    "# boxplot көмегімен визуализациялаймыз\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=df_outliers, x='value')\n",
    "plt.title('Box Plot көмегімен шығарындыларды анықтау')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7e372",
   "metadata": {},
   "source": [
    "#### Практикалық мысал: Квартиларалық ауқым (IQR) әдісі бойынша шығарындыларды шектеу\n",
    "\n",
    "Бұл әдіс boxplot-тағы \"мұртшалардың\" статистикалық аналогы болып табылады. Шығарындылар деп мына шектерден тыс жатқан барлық нүктелер саналады:\n",
    "\n",
    "<br>\n",
    "$$ Төменгі\\_шек = Q1 - 1.5 \\cdot IQR $$\n",
    "<br>\n",
    "$$ Жоғарғы\\_шек = Q3 + 1.5 \\cdot IQR $$\n",
    "<br>\n",
    "\n",
    "мұндағы $Q1$ — 25-ші перцентиль, $Q3$ — 75-ші перцентиль, $IQR = Q3 - Q1$. Жоюдың орнына, біз мәндерді \"шектей\" аламыз, яғни шектен шығатын барлық мәндерді шекаралық мәндермен алмастырамыз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7360018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шектерді есептейміз\n",
    "Q1 = df_outliers['value'].quantile(0.25)\n",
    "Q3 = df_outliers['value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "print(f\"Төменгі шек: {lower_bound:.2f}\")\n",
    "print(f\"Жоғарғы шек: {upper_bound:.2f}\")\n",
    "\n",
    "# Мәндерді шектейміз (clipping)\n",
    "df_clipped = df_outliers.copy()\n",
    "df_clipped['value'] = df_clipped['value'].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "# Нәтижені визуализациялаймыз\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=df_clipped, x='value')\n",
    "plt.title('Шығарындыларды шектегеннен кейінгі деректер')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c48926",
   "metadata": {},
   "source": [
    "### 1.4. Категориялық деректермен жұмыс\n",
    "\n",
    "**Категориялық деректер** — бұл сандық мәндер емес, белгілерді қамтитын айнымалылар. Олар нысанның қандай да бір топқа жататындығын сипаттайды.\n",
    "\n",
    "Екі негізгі түрі бар:\n",
    "1. **Номиналды (Nominal):** Категориялардың ішкі реті жоқ. *Мысалдар: 'Қала' (Мәскеу, Қазан), 'Жыныс' (Ер, Әйел).*\n",
    "2. **Реттік (Ordinal):** Категориялардың табиғи реті немесе дәрежесі бар. *Мысалдар: 'Өлшем' (S, M, L), 'Баға' (Нашар, Жақсы, Өте жақсы).*\n",
    "\n",
    "Машиналық оқыту модельдерінің көпшілігі сандармен жұмыс істейді, сондықтан мәтіндік категорияларды түрлендіру қажет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df55cc-fd2f-4ecd-9ec2-4642ffee4b78",
   "metadata": {},
   "source": [
    "#### 1.4.0. Сандарды кодтау (Integer/Label Encoding)\n",
    "\n",
    "Бұл түрлендірудің ең қарапайым тәсілі: әрбір бірегей категорияға бүтін сан (0, 1, 2 және т.б.) беріледі.\n",
    "\n",
    "**Алайда, бұл әдісті өте сақтықпен қолдану керек!**\n",
    "\n",
    "**Мәселе: Жалған реттілік**\n",
    "\n",
    "Категорияларға `1`, `2`, `3` сандарын бергенде, машиналық оқыту модельдерінің көпшілігі оларды реттелген шамалар ретінде қабылдайды. Олар `3 > 2 > 1` деп \"ойлайды\".\n",
    "\n",
    "* **Қашан жаман (номиналды деректер үшін):** Егер елдерді кодтасақ: `{'АҚШ': 1, 'Мексика': 2, 'Канада': 3}`, модель \"Канада\" \"Мексикадан\" қандай да бір мағынада \"үлкен\" немесе \"маңызды\" деген қате қорытынды жасауы мүмкін. Бұл деректерге модель сапасына зиян келтіруі мүмкін жалған ақпарат енгізеді.\n",
    "\n",
    "* **Қашан жақсы (реттік деректер үшін):** Егер біздің категорияларымыздың табиғи, логикалық реті болса (мысалы, тағамның ащылық деңгейі), онда сандармен кодтау дұрыс таңдау болады. Бұл жағдайда `{'Mild': 1, 'Hot': 2, 'Fire': 3}` реті модель үшін пайдалы ақпарат береді.\n",
    "\n",
    "**Қорытынды:** Сандармен кодтауды тек **реттік (ordinal)** белгілер үшін қолданыңыз. **Номиналды (nominal)** белгілер үшін бұл әдіс, әдетте, зиянды."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fd8a9-89bd-4d53-90d4-ddd941bdee6d",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-14.png\" alt=\"Елдерді кодтау\" width=\"400\"></td>\n",
    "    <td><img src=\"https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-16.png\" alt=\"Ащылықты кодтау\" width=\"400\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8af117",
   "metadata": {},
   "source": [
    "#### 1.4.1. Үздіксіз деректерді категорияларға түрлендіру (Binning)\n",
    "\n",
    "Кейде үздіксіз белгіні (мысалы, жас) категориялыққа айналдыру пайдалы. Бұл процесс **дискретизация** немесе **биннинг** (ағылш. *bin* — себет) деп аталады. Бұл модельге бастапқы деректерде байқай алмаған сызықтық емес тәуелділіктерді ұстауға көмектесуі мүмкін. Мысалы, жастың қандай да бір көрсеткішке әсері сызықтық емес болуы мүмкін: алдымен ол өседі, ал белгілі бір нүктеден кейін төмендей бастайды. Жас топтарын ('Жас', 'Ересек', 'Егде') құру модельге әр топқа өзінің жеке, тәуелсіз салмағын беруге мүмкіндік береді."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8e467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Әртүрлі жастағы серия құрайық\n",
    "ages = pd.Series([15, 22, 35, 48, 65, 70, 28, 55])\n",
    "\n",
    "# Жас топтары үшін шекараларды анықтаймыз (биндер)\n",
    "# [0, 18) -> 0-17 жас\n",
    "# [18, 35) -> 18-34 жас\n",
    "# [35, 60) -> 35-59 жас\n",
    "# [60, 100) -> 60-99 жас\n",
    "bins = [0, 18, 35, 60, 100]\n",
    "\n",
    "# Бұл топтар үшін атауларды анықтаймыз\n",
    "labels = ['Бала', 'Жас', 'Ересек', 'Егде']\n",
    "\n",
    "# Деректерді категорияларға бөлу үшін pd.cut функциясын қолданамыз\n",
    "age_groups = pd.cut(ages, bins=bins, labels=labels, right=False)\n",
    "\n",
    "print(\"Бастапқы жас:\")\n",
    "print(ages)\n",
    "print(\"\\nКатегорияларға бөлгеннен кейін (Binning):\")\n",
    "print(age_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08e0e16",
   "metadata": {},
   "source": [
    "#### 1.4.2. Сандық кодтарды категорияларға түрлендіру (Type Conversion)\n",
    "\n",
    "Нақты деректерде категориялық белгілер жиі сандармен кодталған болады. Мысалы, Ames Housing деректер жинағында `MSSubClass` (тұрғын үй түрі) белгісі 20, 30, 60 және т.б. сандармен берілген.\n",
    "\n",
    "**Мәселе:** Егер бұл деректерді сол күйінде қалдырса, машиналық оқыту алгоритмдерінің көпшілігі (әсіресе сызықтық модельдер) оларды үздіксіз сандық айнымалылар ретінде қате түсіндіреді. Модель кластар арасында математикалық тәуелділік бар деп болжауы мүмкін (мысалы, 60 класы 20 класынан 3 есе 'үлкен' немесе 'маңызды'), бірақ шын мәнінде бұл жай ғана бірегей кодтар.\n",
    "\n",
    "**Шешімі:** Мұны болдырмау үшін, Pandas-қа бұл бағанды категориялық ретінде қарастыру керектігін нақты көрсету қажет. Ең сенімді әдіс — One-Hot Encoding қолданбас **бұрын** осы бағанның деректер түрін `object` немесе `str`-ға түрлендіру. Осындай түрлендіруден кейін `pd.get_dummies` функциясы әр санды жеке категория ретінде дұрыс танып, оған өз бинарлы бағанын жасайды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9faa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мәселені имитациялайтын DataFrame құрайық\n",
    "subclass_df = pd.DataFrame({'MSSubClass': [20, 30, 60, 20, 70]})\n",
    "\n",
    "print(\"Бастапқы DataFrame және деректер түрі:\")\n",
    "print(subclass_df)\n",
    "print(f\"Бағанның деректер түрі: {subclass_df['MSSubClass'].dtype}\")\n",
    "\n",
    "# --- ДҰРЫС ТӘСІЛ ---\n",
    "\n",
    "# 1-қадам: Деректер түрін 'object' (немесе 'str')-ға түрлендіреміз\n",
    "subclass_df['MSSubClass'] = subclass_df['MSSubClass'].astype(str)\n",
    "\n",
    "print(\"\\nТүрлендіруден кейінгі деректер түрі:\")\n",
    "print(f\"Бағанның жаңа деректер түрі: {subclass_df['MSSubClass'].dtype}\")\n",
    "\n",
    "# 2-қадам: Енді One-Hot Encoding қолданамыз\n",
    "dummies = pd.get_dummies(subclass_df, drop_first=True)\n",
    "\n",
    "print(\"\\nДұрыс түрлендіруден кейінгі One-Hot Encoding нәтижесі:\")\n",
    "print(dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baadce5",
   "metadata": {},
   "source": [
    "#### 1.4.3. Номиналды белгілер үшін One-Hot Encoding\n",
    "\n",
    "**Номиналды** белгілер үшін (реті жоқ жерде) **One-Hot Encoding** қолданылады. Ол әрбір категория үшін жаңа бинарлы баған (0 немесе 1) жасайды. Бұл осындай деректерді кодтаудың стандартты және ең қауіпсіз тәсілі."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd897f7c-d429-4344-ae29-c562eacbbcbb",
   "metadata": {},
   "source": [
    "![OHE](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-19.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5957ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Қалалармен мысал\n",
    "cities = pd.Series(['Almaty', 'Astana', 'Almaty', 'Astana', 'Shymkent'])\n",
    "\n",
    "print(\"Бастапқы деректер:\")\n",
    "print(cities)\n",
    "\n",
    "print(\"\\nOne-Hot Encoding-тен кейін (бірінші бағанды жою арқылы):\")\n",
    "# drop_first=True, фиктивті айнымалылар тұзағынан аулақ болу үшін\n",
    "print(pd.get_dummies(cities, drop_first=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9fdc5",
   "metadata": {},
   "source": [
    "## 2-бөлім: Логистикалық регрессия\n",
    "\n",
    "Нақты алгоритмді зерттемес бұрын, қандай есепті шешетінімізді нақты анықтап алайық.\n",
    "\n",
    "### Классификация есебі\n",
    "\n",
    "**Классификация (Classification)** — бұл мұғаліммен оқытудың негізгі есептерінің бірі. Оның мақсаты — нысанның алдын ала анықталған бірнеше **класстардың** (категориялардың) қайсысына жататынын болжау. Үздіксіз санды (мысалы, үй бағасын) болжайтын регрессия есебінен айырмашылығы, мұнда біз дискретті белгіні болжаймыз.\n",
    "\n",
    "* **Регрессия \"Қанша?\" деген сұраққа жауап береді:** *Пәтер қанша тұрады? Ертең ауа температурасы қандай болады?*\n",
    "* **Классификация \"Қандай?\" деген сұраққа жауап береді:** *Бұл хат — спам ба, жоқ па? Суретте қандай жануар бар?*\n",
    "\n",
    "### Классификация есептерінің түрлері\n",
    "\n",
    "Классификация есептері екі негізгі түрге бөлінеді:\n",
    "\n",
    "1. **Бинарлы классификация (Binary Classification):**\n",
    " * **Бұл не:** Дәл екі өзара бірін-бірі жоққа шығаратын класс бар есеп. Бұл классификацияның ең кең таралған түрі.\n",
    " * **Мысалдар:**\n",
    " * Медициналық диагноз: ауру бар (`1`) немесе жоқ (`0`).\n",
    " * Спам-сүзгі: хат спам болып табылады (`1`) немесе жоқ (`0`).\n",
    " * Банктік скоринг: клиент несиені қайтарады (`1`) немесе қайтармайды (`0`).\n",
    " * Маркетинг: пайдаланушы жарнаманы басады (`1`) немесе баспайды (`0`).\n",
    "\n",
    "2. **Көп класты классификация (Multiclass Classification):**\n",
    " * **Бұл не:** Екіден көп өзара бірін-бірі жоққа шығаратын класс бар есеп. Нысан олардың тек біреуіне ғана тиесілі бола алады.\n",
    " * **Мысалдар:**\n",
    " * Қолжазба сандарды тану: `0`, `1`, `2`, ..., `9`.\n",
    " * Жаңалықтарды тақырыптар бойынша жіктеу: 'Саясат', 'Спорт', 'Технологиялар', 'Мәдениет'.\n",
    " * Мәтіннің тоналдығын талдау: 'Позитивті', 'Бейтарап', 'Негативті'.\n",
    " * Ирис гүлдерін жіктеу (кейінірек көретініміздей): 'Setosa', 'Versicolor', 'Virginica'.\n",
    "\n",
    "### Логистикалық регрессия: Бинарлы классификацияның негізгі құралы\n",
    "\n",
    "**Бинарлы классификация** есептерін шешуге арналған негізгі және ең жиі қолданылатын алгоритм — **логистикалық регрессия**. Атауында \"регрессия\" сөзі болғанына қарамастан, бұл нысанның екі кластың біріне жату ықтималдығын болжайтын классификация әдісі болып табылады.\n",
    "\n",
    "Оның негізгі мақсаты бинарлы классификация болғанымен, оны көп класты есептерді шешуге де кеңейтуге мүмкіндік беретін әдістер бар (мысалы, One-vs-Rest), мұны біз Фишердің Ирис деректер жинағы мысалында қарастырамыз."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faca6ca8",
   "metadata": {},
   "source": [
    "### 2.1. Регрессиядан классификацияға\n",
    "\n",
    "Бізде студенттер туралы деректер (дайындық сағаттары) және емтихан нәтижесі (тапсырды/тапсырмады) бар деп елестетейік. Сызықтық регрессия мұнда сәйкес келмейді, себебі оның болжамдары [0, 1] аралығынан шығып кетуі мүмкін."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333cbc1-1d0c-4dbd-92ea-677b1ec3c59d",
   "metadata": {},
   "source": [
    "![linear-to-logitic](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-37.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675442e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Синтетикалық деректер\n",
    "hours = np.array([0.5, 0.75, 1, 1.25, 1.5, 1.75, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 4, 4.25, 4.5, 4.75, 5, 5.5]).reshape(-1, 1)\n",
    "passed = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1])\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(hours, passed)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(hours, passed, color='blue', label='Деректер')\n",
    "plt.plot(hours, lin_reg.predict(hours), color='red', label='Сызықтық регрессия')\n",
    "plt.axhline(y=0, color='grey', linestyle='--')\n",
    "plt.axhline(y=1, color='grey', linestyle='--')\n",
    "plt.title('Неліктен сызықтық регрессия классификацияға сәйкес келмейді')\n",
    "plt.xlabel('Дайындық сағаттары')\n",
    "plt.ylabel('Нәтиже (0 - тапсырмады, 1 - тапсырды)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8b2cb1",
   "metadata": {},
   "source": [
    "### 2.2. Логистикалық функция (Сигмоида)\n",
    "\n",
    "Шешім — сызықтық модельдің шығысын S-тәрізді **сигмоида** арқылы өткізу, ол кез келген санды 0-ден 1-ге дейінгі ықтималдыққа түрлендіреді.\n",
    "\n",
    "<br>\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e4494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "z = np.linspace(-10, 10, 100)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(z, sigmoid(z))\n",
    "plt.title('Сигмоидалық функцияның графигі')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('$\\sigma(z)$')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847f7621-6634-4ad1-9cee-47e606392439",
   "metadata": {},
   "source": [
    "Мысал: income = 1. Несиені қайтару ықтималдығы - 90%\n",
    "\n",
    "![ExmplPossibility](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f8b51",
   "metadata": {},
   "source": [
    "### 2.3. Логистикалық регрессия теңдеуі\n",
    "\n",
    "Біз $z = w_0 + w_1x_1 + ...$ сызықтық бөлігін сигмоидаға қоямыз. Модель '1' класына жату ықтималдығын болжайды."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3322ff33-c94f-4afb-9b60-3bbe5382ffd2",
   "metadata": {},
   "source": [
    "![Формула](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-48.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319590d-a504-4c8e-b7c6-58e9acabf768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(hours, passed)\n",
    "\n",
    "# График үшін тегіс қисық құрамыз\n",
    "x_test = np.linspace(0, 6, 100).reshape(-1, 1)\n",
    "y_prob = log_reg.predict_proba(x_test)[:, 1] # 1 класының ықтималдығы\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(hours, passed, color='blue', label='Деректер')\n",
    "plt.plot(x_test, y_prob, color='green', label='Логистикалық регрессия')\n",
    "plt.title('Классификация үшін логистикалық регрессия')\n",
    "plt.xlabel('Дайындық сағаттары')\n",
    "plt.ylabel('Емтиханды тапсыру ықтималдығы')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841f4f74-2849-4412-ad6d-bba42ccd8ac3",
   "metadata": {},
   "source": [
    "2.3.1. Интерпретация: Ықтималдықтан Log-Odds-қа және керісінше\n",
    "\n",
    "Сызықтық регрессиядан айырмашылығы, логистикалық регрессияның $w_i$ коэффициенттерін тікелей \"$x_i$ бірлікке өзгергенде $y$-тің өзгеруі\" деп түсіндіруге болмайды. Олар нәтижеге сигмоида арқылы сызықтық емес әсер етеді. Олардың мағынасын түсіну үшін **Мүмкіндіктер (Odds)** және **Мүмкіндіктер логарифмі (Log-Odds)** ұғымдарын енгізу керек.\n",
    "\n",
    "**1-қадам: Ықтималдықтан Мүмкіндіктерге (Odds)**\n",
    "\n",
    "Мүмкіндіктер — бұл оқиғаның болу ықтималдығының оның болмау ықтималдығына қатынасы. Егер емтиханды тапсыру ықтималдығы ($p$) 0.8-ге тең болса, онда тапсырмау ықтималдығы ($1-p$) 0.2-ге тең. Тапсыру мүмкіндіктері 0.8 / 0.2 = 4, немесе \"4-тің 1-ге\" қатынасы.\n",
    "\n",
    "<br>\n",
    "$$ Odds = \\frac{p}{1 - p} $$\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33add5c1-8b54-4212-ad42-118518f42bc4",
   "metadata": {},
   "source": [
    "**2-қадам: Мүмкіндіктерден Мүмкіндіктер логарифміне (Log-Odds)**\n",
    "\n",
    "Мүмкіндіктерден натуралды логарифм алсақ, біз $-\\infty$-ден $+\\infty$-ге дейін өзгеретін шаманы аламыз. Бұл — **Log-Odds**.\n",
    "\n",
    "<br>\n",
    "$$ Log\\_Odds = \\ln\\left(\\frac{p}{1 - p}\\right) $$\n",
    "<br>\n",
    "\n",
    "**Логистикалық регрессияның негізгі идеясы:** Белгілердің $z = w_0 + w_1x_1 + ... + w_mx_m$ сызықтық комбинациясы шын мәнінде ықтималдықтың өзіне емес, **мүмкіндіктер логарифміне** арналған модель болып табылады.\n",
    "\n",
    "<br>\n",
    "$$ \\ln\\left(\\frac{p}{1 - p}\\right) = w_0 + w_1x_1 + ... + w_mx_m $$\n",
    "<br>\n",
    "\n",
    "Бұл $x_i$ белгісі бір бірлікке артқанда, **мүмкіндіктер логарифмі** $w_i$-ге артатынын білдіреді.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7967ae-80c5-464b-b010-70b65e6e044e",
   "metadata": {},
   "source": [
    "![logodds](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-71.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb33b7-2900-4a28-97b9-5586949c5ac8",
   "metadata": {},
   "source": [
    "**3-қадам: Кері жол — Log-Odds-тан Ықтималдыққа**\n",
    "\n",
    "Модельмен болжанған Log-Odds ($z$) арқылы ықтималдықты ($p$) қалай алуға болады? Жоғарыдағы теңдеуден $p$-ны өрнектейік:\n",
    "\n",
    "1. Екі жағынан да экспонента аламыз: $$ \\frac{p}{1 - p} = e^z $$\n",
    "2. $(1-p)$-ға көбейтеміз: $$ p = e^z \\cdot (1-p) $$\n",
    "3. Жақшаларды ашамыз: $$ p = e^z - p \\cdot e^z $$\n",
    "4. $p$ бар барлық қосылғыштарды солға көшіреміз: $$ p + p \\cdot e^z = e^z $$\n",
    "5. $p$-ны жақша сыртына шығарамыз: $$ p(1 + e^z) = e^z $$\n",
    "6. Соңғы формуланы аламыз: $$ p = \\frac{e^z}{1 + e^z} $$\n",
    "\n",
    "Егер алымын да, бөлімін де $e^z$-ке бөлсек, біз бұрыннан таныс сигмоида формуласын аламыз:\n",
    "\n",
    "<br>\n",
    "$$ p = \\frac{e^z/e^z}{(1+e^z)/e^z} = \\frac{1}{1/e^z + 1} = \\frac{1}{1 + e^{-z}} = \\sigma(z) $$\n",
    "<br>\n",
    "\n",
    "Осылайша, **сигмоида — бұл модельмен болжанған Log-Odds-тан ықтималдыққа кері өтудің математикалық тәсілі.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2947f284-58d1-4759-bd93-085ad513f9c5",
   "metadata": {},
   "source": [
    "### 2.4. Модельді оқыту: Максималды шындыққа жанасымдылық әдісі және Log Loss\n",
    "\n",
    "Модель оңтайлы `w` салмақтарын қалай табады? Біз қателердің квадраттарының қосындысын (MSE) минимизациялаған сызықтық регрессиядан айырмашылығы, логистикалық регрессияда **Максималды шындыққа жанасымдылық әдісі (Maximum Likelihood Estimation, MLE)** қолданылады."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89db168-50a5-4819-9d6f-7a79233d6db3",
   "metadata": {},
   "source": [
    "![whatisthebest](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-77.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794cc93c-8a1b-4c81-bc0b-49157fcb179b",
   "metadata": {},
   "source": [
    "\n",
    "**Қарапайым мысалмен интуиция:**\n",
    "Сіз тиынды 10 рет лақтырып, 7 рет бүркіт, 3 рет жазу алдыңыз деп елестетіңіз. Сіздің ойыңызша, бүркіттің түсу ықтималдығы ($p$) қандай? Көпшілігі 0.7 деп айтады. Сіз интуитивті түрде MLE-ді қолдандыңыз.\n",
    "\n",
    "**MLE логикасы:** Параметрдің ($p$) сондай мәнін табайық, онда **дәл біз бақылаған деректерді** алу ықтималдығы максималды болады.\n",
    "* Егер $p=0.5$ (әділ тиын) болса, біздің тізбегіміздің ықтималдығы $(0.5)^7 \\cdot (1-0.5)^3 \\approx 0.00097$ болар еді.\n",
    "* Егер $p=0.7$ болса, біздің тізбегіміздің ықтималдығы $(0.7)^7 \\cdot (1-0.7)^3 \\approx 0.00222$ болар еді.\n",
    "\n",
    "$p=0.7$ болғанда ықтималдық жоғары. MLE — бұл ықтималдықты (шындыққа жанасымдылықты) максимизациялайтын $p$-ны табу процесі.\n",
    "\n",
    "**Логистикалық регрессияға қатысты:** Алгоритм оқыту таңдамасының әрбір нысаны үшін модельдің оның шын белгісіне жақын ықтималдық (яғни '1' класы үшін 1-ге жақын және '0' класы үшін 0-ге жақын) беруінің шындыққа жанасымдылығын максимизациялайтын `w` салмақтарын таңдайды.\n",
    "\n",
    "Математикалық тұрғыдан, шындыққа жанасымдылықты максимизациялау теріс логарифмдік шындыққа жанасымдылықты минимизациялауға эквивалентті. Логистикалық регрессия үшін бұл шығын функциясы **Log Loss** (немесе бинарлы кросс-энтропия) деп аталады.\n",
    "\n",
    "Бұл функцияның **бір** нысан үшін көрінісі:\n",
    "\n",
    "<br>\n",
    "$$ Loss(y, \\hat{p}) = -[y \\cdot \\log(\\hat{p}) + (1 - y) \\cdot \\log(1 - \\hat{p})] $$\n",
    "<br>\n",
    "\n",
    "мұндағы:\n",
    "* $y$ — шын класс белгісі (0 немесе 1).\n",
    "* $\\hat{p}$ — модельмен болжанған, нысанның 1 класына жату ықтималдығы.\n",
    "\n",
    "**Оның қалай жұмыс істейтінін түсінейік:**\n",
    "\n",
    "* **1-жағдай: Шын белгі y = 1.**\n",
    "  Формула $Loss(1, \\hat{p}) = -[1 \\cdot \\log(\\hat{p}) + (0) \\cdot \\log(1 - \\hat{p})] = -\\log(\\hat{p})$ дейін жеңілдейді.\n",
    "  Бұл шығынды минимизациялау үшін $-\\log(\\hat{p})$ мәні мүмкіндігінше аз болуы керек. Бұл $\\log(\\hat{p})$ максималды болғанда, яғни $\\hat{p}$ **1**-ге ұмтылғанда орындалады. Бұл бізге дәл қажет нәрсе!\n",
    "\n",
    "* **2-жағдай: Шын белгі y = 0.**\n",
    "  Формула $Loss(0, \\hat{p}) = -[0 \\cdot \\log(\\hat{p}) + (1) \\cdot \\log(1 - \\hat{p})] = -\\log(1 - \\hat{p})$ дейін жеңілдейді.\n",
    "  Бұл шығынды минимизациялау үшін $-\\log(1 - \\hat{p})$ мәні мүмкіндігінше аз болуы керек. Бұл $\\log(1 - \\hat{p})$ максималды болғанда, яғни $1 - \\hat{p}$ 1-ге ұмтылғанда, ал $\\hat{p}$ өзі — **0**-ге ұмтылғанда орындалады. Тағы да, бұл бізге дәл қажет нәрсе!\n",
    "\n",
    "N нысаннан тұратын бүкіл оқыту таңдамасы үшін жалпы **құн функциясын (Cost Function)** алу үшін біз бұл шығынды жай ғана орташалаймыз:\n",
    "\n",
    "<br>\n",
    "$$ J(w) = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\cdot \\log(\\hat{p}_i) + (1 - y_i) \\cdot \\log(1 - \\hat{p}_i)] $$\n",
    "<br>\n",
    "\n",
    "Болжанған ықтималдық $\\hat{p}_i$ сигмоидалық функцияны белгілердің сызықтық комбинациясына қолдану нәтижесі болғандықтан ($\\hat{p}_i = \\sigma(w^T x_i)$), минимизациялау қажет құн функциясының толық формуласы келесідей болады:\n",
    "\n",
    "<br>\n",
    "$$ J(w) = -\\frac{1}{N} \\sum_{i=1}^{N} \\left[ y_i \\cdot \\log\\left( \\frac{1}{1 + e^{-w^T x_i}} \\right) + (1 - y_i) \\cdot \\log\\left(1 - \\frac{1}{1 + e^{-w^T x_i}}\\right) \\right] $$\n",
    "<br>\n",
    "\n",
    "Бұл формула күрделі көрінгенімен, ол дөңес болып табылады, бұл жалғыз ғаламдық минимумның болуына кепілдік береді. Сызықтық регрессиядағыдай, осы минимумды (яғни оңтайлы `w` салмақтарын) табу үшін **градиенттік түсу әдісі** қолданылады."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21689892-d0b9-40df-a549-1bc7090fe7ae",
   "metadata": {},
   "source": [
    "![logodds-p](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91450db2",
   "metadata": {},
   "source": [
    "### 2.5. Көп класты Логистикалық Регрессия\n",
    "\n",
    "Егер бізде екіден көп класс болса не істеу керек? Стандартты тәсіл **One-vs-Rest (OvR) (Біреуі қалғандарына қарсы)** деп аталады. K класс үшін K бинарлы классификатор құрылады: біріншісі 1-класты қалғандарынан ажыратады, екіншісі — 2-класты қалғандарынан, және осылай жалғасады. Жаңа нысан үшін барлық K классификатор іске қосылады, және ең жоғары сенімділікті (ықтималдықты) бергені таңдалады.\n",
    "\n",
    "Мұны классикалық **Фишердің Ирис** деректер жинағында қарастырайық."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdef0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "df_iris = pd.DataFrame(X_iris, columns=iris.feature_names)\n",
    "df_iris['species'] = y_iris\n",
    "\n",
    "# Көрнекілік үшін сандық белгілерді атаулармен алмастырамыз\n",
    "target_names = iris.target_names\n",
    "df_iris['species'] = df_iris['species'].apply(lambda x: target_names[x])\n",
    "\n",
    "print(\"Фишердің Ирис деректер жинағының алғашқы 5 жолы:\")\n",
    "print(df_iris.head())\n",
    "\n",
    "sns.pairplot(df_iris, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fbe17f",
   "metadata": {},
   "source": [
    "`pairplot`-тан `setosa` класы оңай бөлінетіні, ал `versicolor` мен `virginica` ішінара қиылысатыны көрінеді. Барлық үш класты бөлу үшін модельді оқытайық."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b36633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Деректерді дайындау\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(X_iris, y_iris, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler_iris = StandardScaler()\n",
    "X_train_iris_scaled = scaler_iris.fit_transform(X_train_iris)\n",
    "X_test_iris_scaled = scaler_iris.transform(X_test_iris)\n",
    "\n",
    "# Модельді оқыту. Scikit-learn көп класты есеп үшін OvR-ді автоматты түрде қолданады.\n",
    "log_reg_multi = LogisticRegression()\n",
    "log_reg_multi.fit(X_train_iris_scaled, y_train_iris)\n",
    "\n",
    "# Бағалау\n",
    "y_pred_iris = log_reg_multi.predict(X_test_iris_scaled)\n",
    "\n",
    "print(\"Фишердің Иристері үшін қателіктер матрицасы:\")\n",
    "print(confusion_matrix(y_test_iris, y_pred_iris))\n",
    "print(\"\\nКлассификация есебі:\")\n",
    "print(classification_report(y_test_iris, y_pred_iris, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea90c0c9",
   "metadata": {},
   "source": [
    "## 3-бөлім: Классификация модельдерін бағалау метрикалары\n",
    "\n",
    "Регрессияға арналған метрикалар (MAE, RMSE) мұнда сәйкес келмейді. Классификация үшін **Қателіктер матрицасына (Confusion Matrix)** негізделген өз метрикалар жиынтығы қолданылады."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f923d3aa",
   "metadata": {},
   "source": [
    "### 3.1. Қателіктер матрицасы (Confusion Matrix)\n",
    "\n",
    "Бұл кесте модельдің әрбір класс үшін қанша болжамды дұрыс, қаншасын қате жасағанын көрсетеді. Ол барлық басқа метрикалардың негізі болып табылады.\n",
    "\n",
    "* **True Positive (TP):** Ақиқат-оң. Модель '1' деп болжады, және ол шын мәнінде '1' болды.\n",
    "* **True Negative (TN):** Ақиқат-теріс. Модель '0' деп болжады, және ол шын мәнінде '0' болды.\n",
    "* **False Positive (FP):** Жалған-оң (I-түрдегі қате). Модель '1' деп болжады, бірақ шын мәнінде ол '0' болды.\n",
    "* **False Negative (FN):** Жалған-теріс (II-түрдегі қате). Модель '0' деп болжады, бірақ шын мәнінде ол '1' болды."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d27f1c-593b-46e8-b500-cdf5fb6c2135",
   "metadata": {},
   "source": [
    "![confusionmatrix](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-126.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da37fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Шамамен алынған шын мәндер мен болжамдар\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
    "y_pred = [1, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Класс 0', 'Класс 1'], yticklabels=['Класс 0', 'Класс 1'])\n",
    "plt.xlabel('Болжанған мәндер')\n",
    "plt.ylabel('Шын мәндер')\n",
    "plt.title('Қателіктер матрицасы')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee331f4a-99b4-49e8-a0a0-b61aaa51d99b",
   "metadata": {},
   "source": [
    "### 3.2. Негізгі метрикалар\n",
    "\n",
    "#### **Accuracy (Дұрыс жауаптар үлесі)**\n",
    "* **Сұрақ:** Жалпы бақылаулар санындағы барлық дұрыс болжамдардың (оң және теріс) үлесі қандай?\n",
    "* **Формула:** $$ Accuracy = \\frac{TP+TN}{TP+TN+FP+FN} $$\n",
    "* **Диапазон:** 0-ден 1-ге дейін (немесе 0%-дан 100%-ға дейін).\n",
    " * **1-ге жақын:** Модель жалпы алғанда көптеген дұрыс болжамдар жасайды.\n",
    " * **0-ге жақын:** Модель жиі қателеседі.\n",
    "* **Интерпретация:** Қарапайым және түсінікті метрика. Алайда, ол **теңгерімсіз деректерде** — бір кластың екіншісінен әлдеқайда көп болған жағдайларда адастыруы мүмкін. Бұл құбылыс **Дәлдік парадоксы** деп аталады.\n",
    "\n",
    "**Дәлдік парадоксының мысалы:**\n",
    "Сирек кездесетін ауруды диагностикалау есебін елестетейік. 1000 адамдық таңдамада: 990-ы сау (0 класы) және 10-ы ауру (1 класы). Біз әрқашан \"сау\" (0 класы) деп болжайтын өте қарапайым (және пайдасыз) модель құрдық.\n",
    "* **TN:** 990 (сау адамдарды дұрыс тапты).\n",
    "* **TP:** 0 (бірде-бір ауру адамды таппады).\n",
    "* **FP:** 0 (ешкімді ауру деп атамады).\n",
    "* **FN:** 10 (барлық ауру адамдарды өткізіп алды).\n",
    "\n",
    "Оның Accuracy-і: $$ Accuracy = \\frac{0 + 990}{0 + 990 + 0 + 10} = \\frac{990}{1000} = 99\\\\% $$. \n",
    "99% дәлдік керемет болып көрінеді, бірақ модель мүлдем пайдасыз, себебі ол басты міндетті — ауруларды табуды — шешпейді. Сондықтан теңгерімсіз деректер үшін `Accuracy`-ді қолдануға болмайды. Басқа метрикалар қажет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c31942-7304-4871-bf90-22982c6739ef",
   "metadata": {},
   "source": [
    "![Precision1](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-134.png)\n",
    "\n",
    "![Precision2](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-137.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a7118-203b-41a7-b0a8-800b463845c7",
   "metadata": {},
   "source": [
    "#### **Recall (Толықтық, немесе Сезімталдық)**\n",
    "* **Сұрақ:** Барлық нақты 'оң' нысандардың ішінен біз қандай үлесін таба алдық?\n",
    "* **Формула:** $$ Recall = \\frac{TP}{TP + FN} $$\n",
    "* **Диапазон:** 0-ден 1-ге дейін.\n",
    " * **1-ге жақын:** Модель оң кластың барлық дерлік нысандарын табады.\n",
    " * **0-ге жақын:** Модель оң кластың көптеген нысандарын өткізіп жібереді.\n",
    "* **Интерпретация:** Recall **False Negative** қатесінің құны жоғары болғанда маңызды. *Мысал: медициналық диагностика. Ауру адамды өткізіп алу (FN) — апат. Біз модельдің мүмкіндігінше көп нақты ауруларды тапқанын қалаймыз, тіпті егер ол кейде сау адамдарды қосымша тексеруге (FP) қате жіберіп отырса да. Мұнда жоғары Recall маңызды.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90379b31-99b4-4794-b147-ca42b729901e",
   "metadata": {},
   "source": [
    "![Recall1](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-146.png)\n",
    "\n",
    "![Recall2](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-148.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5564fb8c-d652-48e9-aa64-e1b5f92b6448",
   "metadata": {},
   "source": [
    "#### **Precision (Дәлдік)**\n",
    "* **Сұрақ:** Модель 'оң' деп атаған барлық нысандардың ішінен қандай үлесі шын мәнінде 'оң' болды?\n",
    "* **Формула:** $$ Precision = \\frac{TP}{TP + FP} $$\n",
    "* **Диапазон:** 0-ден 1-ге дейін.\n",
    " * **1-ге жақын:** Модель өзінің оң болжамдарында өте дәл. Егер ол \"Иә\" десе, оған сенуге болады.\n",
    " * **0-ге жақын:** Модельдің оң болжамдарының көпшілігі — жалған дабылдар.\n",
    "* **Интерпретация:** Precision **False Positive** қатесінің құны жоғары болғанда маңызды. *Мысал: спам-сүзгі. Егер модель маңызды хатты спам деп белгілесе (FP), бұл үлкен мәселе. Біз модельдің өзінің \"спам\"-үкімдеріне өте сенімді болғанын, яғни жоғары Precision-ге ие болғанын қалаймыз.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb16f3c9-05cd-402b-8ed6-1fc6c8080814",
   "metadata": {},
   "source": [
    "![Precision1](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-150.png)\n",
    "\n",
    "![Precision2](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-152.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b339f393-a910-42e4-a559-aeb2524ac180",
   "metadata": {},
   "source": [
    "\n",
    "#### **F1-Score**\n",
    "* **Сұрақ:** Precision мен Recall арасындағы тепе-теңдікті қалай табуға болады?\n",
    "* **Формула:** $$ F1 = 2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall} $$\n",
    "* **Диапазон:** 0-ден 1-ге дейін.\n",
    " * **1-ге жақын:** Модельде дәлдік пен толықтық арасында жақсы тепе-теңдік бар.\n",
    " * **0-ге жақын:** Модельдің не дәлдігі, не толықтығы, немесе екеуі де төмен.\n",
    "* **Интерпретация:** Precision мен Recall арасындағы гармоникалық орташа. Бұл метрика екі қателік те (FP және FN) маңызды болғанда және олардың арасында ымыра табу қажет болғанда пайдалы. Ол метрикалардың бірі (Precision немесе Recall) өте төмен болған модельдерді жазалайды."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cb2439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# y_true and y_pred are defined in the cell with id: 35da37fa\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776690dd",
   "metadata": {},
   "source": [
    "### 3.3. ROC-қисығы және AUC\n",
    "\n",
    "Логистикалық регрессия ықтималдықтарды береді. Класстарды (0 немесе 1) алу үшін біз шекті (әдетте 0.5) қолданамыз. **ROC-қисығы** модельдің *барлық мүмкін* шекті мәндердегі сапасын көрсетеді, True Positive Rate (Recall) мен False Positive Rate арасындағы тәуелділік графигін құрады.\n",
    "\n",
    "**AUC (Қисық астындағы аудан)** — бұл шектен тәуелсіз, интегралды сапа метрикасы.\n",
    "* AUC = 1.0 — идеалды классификатор.\n",
    "* AUC = 0.5 — кездейсоқ болжау."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae750a29-e9cb-4723-85d1-7cb683578b9b",
   "metadata": {},
   "source": [
    "Идеалды ROC & Шынайы ROC\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-177.png\" alt=\"Идеалды\" width=\"400\"></td>\n",
    "    <td><img src=\"https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec8-162.png\" alt=\"Шынайы\" width=\"400\"></td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d988660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "# log_reg, hours, passed айнымалылары 675442e8 және a5ade196-c76f-40ef-9096-b865796133b5 ұяшықтарында анықталған.\n",
    "RocCurveDisplay.from_estimator(log_reg, hours, passed)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Кездейсоқ болжау (AUC = 0.5)')\n",
    "plt.title('ROC-қисығы')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
