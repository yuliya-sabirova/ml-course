{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lab7-intro",
   "metadata": {},
   "source": [
    "# Лабораторная работа 7: Полиномиальная регрессия, регуляризация и кросс-валидация\n",
    "\n",
    "**Цель:** Научиться улучшать базовые модели линейной регрессии, управляя их сложностью и применяя методы для борьбы с переобучением.\n",
    "\n",
    "**Задание:**\n",
    "Эта лабораторная работа является прямым продолжением Лабораторной 6. Вам предстоит взять одну из моделей, которую вы построили ранее, и попытаться улучшить ее качество, используя полиномиальные признаки и регуляризацию.\n",
    "\n",
    "**Выберите один из вариантов, с которым вы работали в Лабораторной 6 (Калифорния, E-commerce или Медицина).**\n",
    "\n",
    "**Шаги:**\n",
    "1.  **Подготовка:** Скопируйте код из Лабораторной 6 для загрузки и базовой подготовки вашего набора данных (создание `X` и `y`, `train_test_split`).\n",
    "2.  **Поиск оптимальной сложности:**\n",
    "    *   Напишите цикл, который перебирает степени полинома от 1 до, например, 5.\n",
    "    *   Внутри цикла создайте конвейер (`pipeline`), состоящий из `StandardScaler`, `PolynomialFeatures` и `LinearRegression`.\n",
    "    *   Обучайте модель на **обучающей** выборке.\n",
    "    *   Считайте ошибку RMSE на **обучающей** и на **тестовой** (или валидационной) выборках.\n",
    "    *   Постройте график кривых обучения (зависимость RMSE от степени полинома для train и test). Определите по графику оптимальную степень полинома.\n",
    "3.  **Регуляризация и подбор гиперпараметров:**\n",
    "    *   Выберите лучшую степень полинома из предыдущего шага.\n",
    "    *   Создайте новый конвейер, но теперь вместо `LinearRegression` используйте `ElasticNet`.\n",
    "    *   Создайте сетку гиперпараметров (`param_grid`) для `alpha` и `l1_ratio` модели `ElasticNet`.\n",
    "    *   Используйте `GridSearchCV` с `cv=5` (или 10) для поиска наилучшей комбинации гиперпараметров на **обучающей выборке**.\n",
    "4.  **Финальная оценка:**\n",
    "    *   Возьмите лучшую модель, найденную `GridSearchCV` (`grid_search.best_estimator_`).\n",
    "    *   Оцените ее финальное качество (RMSE, MAE, R²) на **тестовой выборке**.\n",
    "    *   Сравните полученные метрики с метриками простой линейной регрессии из Лабораторной 6. Сделайте вывод: удалось ли улучшить модель?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lab7-template-md",
   "metadata": {},
   "source": [
    "### Примерная структура кода для выполнения задания\n",
    "\n",
    "Ниже приведен шаблон, который вы можете адаптировать для своего набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lab7-template-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# --- ШАГ 1: ПОДГОТОВКА ДАННЫХ ---\n",
    "# Загрузите и подготовьте ваш DataFrame df\n",
    "# ...\n",
    "\n",
    "# X = ...\n",
    "# y = ...\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# --- ШАГ 2: ПОИСК ОПТИМАЛЬНОЙ СЛОЖНОСТИ ---\n",
    "# train_rmse_errors = []\n",
    "# test_rmse_errors = []\n",
    "# degrees = range(1, 6)\n",
    "\n",
    "# for d in degrees:\n",
    "#     poly_model = make_pipeline(StandardScaler(), \n",
    "#                                PolynomialFeatures(degree=d), \n",
    "#                                LinearRegression())\n",
    "#     poly_model.fit(X_train, y_train)\n",
    "    \n",
    "#     # ... считаем и сохраняем ошибки ...\n",
    "\n",
    "# # ... строим график кривых обучения ...\n",
    "\n",
    "\n",
    "# --- ШАГ 3: РЕГУЛЯРИЗАЦИЯ И ПОДБОР ГИПЕРПАРАМЕТРОВ ---\n",
    "# best_degree = ... # Выберите лучшую степень с графика\n",
    "\n",
    "# elastic_pipe = make_pipeline(StandardScaler(),\n",
    "#                              PolynomialFeatures(degree=best_degree),\n",
    "#                              ElasticNet(max_iter=10000))\n",
    "\n",
    "# param_grid = {\n",
    "#     'elasticnet__alpha': [0.01, 0.1, 1, 5, 10],\n",
    "#     'elasticnet__l1_ratio': [0.5, 0.75, 0.9, 0.99, 1]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator=elastic_pipe, \n",
    "#                            param_grid=param_grid, \n",
    "#                            cv=5, \n",
    "#                            scoring='neg_mean_squared_error')\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# --- ШАГ 4: ФИНАЛЬНАЯ ОЦЕНКА ---\n",
    "# print(\"Лучшие параметры для ElasticNet:\", grid_search.best_params_)\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "# y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# final_rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))\n",
    "# print(f\"Финальный RMSE на тестовой выборке: {final_rmse:.2f}\")\n",
    "\n",
    "# ... Сравните с результатом из Лаб. 6 ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
