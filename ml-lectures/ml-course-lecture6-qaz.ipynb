{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "25293088-revised",
      "metadata": {},
      "source": [
        "# 6-дәріс: Supervised Learning негіздері және Сызықтық регрессия\n",
        "\n",
        "**Дәріс мақсаттары:**\n",
        "1.  Машиналық оқытудың негізгі парадигмалары және мұғаліммен оқытудың орны туралы түсінік қалыптастыру.\n",
        "2.  ML-жобасының стандартты өмірлік циклін (CRISP-DM) егжей-тегжейлі зерттеу.\n",
        "3.  Деректерді дайындаудың негізгі кезеңдері ретінде деректерді бөлудің және белгілерді масштабтаудың маңыздылығын түсіну.\n",
        "4.  Сызықтық регрессия әдісінің математикалық негіздерін және интерпретациясын тереңінен зерттеу.\n",
        "5.  Шығын функциясы (MSE) концепциясын меңгеру және регрессиялық модельдердің сапасын бағалаудың негізгі метрикаларымен (MAE, RMSE, R²) танысу."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90b5e914",
      "metadata": {},
      "source": [
        "## 1. Machine Learning әлемінің картасы\n",
        "\n",
        "Нақты бір әдіске тереңдемес бұрын, біз қайда екенімізді және қайда бара жатқанымызды түсіну үшін машиналық оқытуға (ML) жоғарыдан көз жүгіртейік.\n",
        "\n",
        "**Машиналық оқыту** — бұл жасанды интеллект саласы, ол компьютерлерге деректер негізінде оқуға, олардағы заңдылықтарды анықтауға және әрбір нақты тапсырма үшін нақты бағдарламалаусыз шешім қабылдауға мүмкіндік береді."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde011f0",
      "metadata": {},
      "source": [
        "### 1.1. ML әдістерінің классификациясы\n",
        "\n",
        "Барлық әдістерді шартты түрде үш үлкен парадигмаға бөлуге болады:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cde011f0",
      "metadata": {},
      "source": [
        "#### 1.1.1. Мұғаліммен оқыту (Supervised Learning)\n",
        "\n",
        "*   **Мәні:** Бізде әрбір нысан үшін (**белгілер**, `X`) дұрыс жауап (**нысаналы айнымалы**, `y`) белгілі деректер жиынтығы бар. Модель, ынталы оқушы сияқты, осы мысалдардан `y ≈ f(X)` тәуелділігін табуды үйренеді.\n",
        "*   **Аналогия:** Оқушыға жануарлардың суреттері (`X`) атауларымен (`y`) беріледі. Оқытудан кейін ол бұрын көрмеген жаңа суреттегі жануарды атай білуі керек.\n",
        "\n",
        "**Supervised Learning негізгі міндеттері:**\n",
        "\n",
        "1.  **Регрессия (Regression):**\n",
        "    *   **Мақсаты:** **Үздіксіз** (сандық) нысаналы айнымалы `y`-ті болжау.\n",
        "    *   **Мысалдар:**\n",
        "        *   Пәтердің бағасын оның ауданы, ауданы, бөлмелер саны бойынша болжау.\n",
        "        *   Ертеңгі ауа температурасын болжау.\n",
        "        *   Келесі айдағы тауарға сұранысты бағалау.\n",
        "    *   **Картадағы орнымыз:** **Бүгін біз дәл осымен айналысамыз.**\n",
        "\n",
        "2.  **Классификация (Classification):**\n",
        "    *   **Мақсаты:** **Категориялық** нысаналы айнымалы `y`-ті (класс белгісін) болжау.\n",
        "    *   **Мысалдар:**\n",
        "        *   Электрондық поштаның спам екенін немесе жоқ екенін анықтау (2 класс).\n",
        "        *   Суреттегі санды тану (10 класс: 0-ден 9-ға дейін).\n",
        "        *   Медициналық талдаулар бойынша ауруды диагностикалау (бірнеше класс: сау, А түрімен ауырады, Б түрімен ауырады)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a2d3ae",
      "metadata": {},
      "source": [
        "#### 1.1.2. Мұғалімсіз оқыту (Unsupervised Learning)\n",
        "\n",
        "*   **Мәні:** Бізде тек нысандар туралы деректер (`X`) бар, ешқандай \"дұрыс жауаптарсыз\". Модель деректерден ішкі құрылымдарды, жасырын заңдылықтарды немесе ауытқуларды өздігінен табуға тырысады.\n",
        "*   **Аналогия:** Оқушыға сол жануарлардың суреттері беріледі, бірақ атауларсыз. Ол \"мысықтар\" немесе \"иттер\" кім екенін білмейді, бірақ оларды бір-біріне ұқсайтын топтарға сұрыптай алады.\n",
        "\n",
        "**Unsupervised Learning негізгі міндеттері:**\n",
        "\n",
        "1.  **Кластерлеу (Clustering):**\n",
        "    *   **Мақсаты:** Барлық нысандарды топтарға (кластерлерге) бөлу, осылайша бір топтағы нысандар барынша ұқсас, ал әртүрлі топтардағы нысандар барынша әртүрлі болады.\n",
        "    *   **Мысал:** Мақсатты маркетингтік кампанияларды жүргізу үшін интернет-дүкен клиенттерін олардың мінез-құлқы бойынша сегменттеу.\n",
        "\n",
        "2.  **Өлшемділікті азайту (Dimensionality Reduction):**\n",
        "    *   **Мақсаты:** Белгілер санын азайту, бірақ сонымен бірге мүмкіндігінше көп пайдалы ақпаратты сақтау.\n",
        "    *   **Мысал:** Көп өлшемді деректерді 2D-графикте визуализациялау немесе суреттерді сығу."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8c47d1e",
      "metadata": {},
      "source": [
        "#### 1.1.3. Нығайту арқылы оқыту (Reinforcement Learning)\n",
        "\n",
        "*   **Мәні:** Модель (агент) белгілі бір ортамен өзара әрекеттесу арқылы үйренеді. Дұрыс әрекеттер үшін ол \"марапат\" (reward), ал қате әрекеттер үшін \"айыппұл\" (penalty) алады. Агенттің мақсаты — қорытынды марапатты барынша арттыратын мінез-құлық стратегиясын әзірлеу.\n",
        "*   **Аналогия:** Итті үйрету. Орындалған команда (\"отыр\") үшін ол дәмді тамақ (марапат) алады, ал орындалмағаны үшін — ештеңе алмайды.\n",
        "\n",
        "**Мысалдар:**\n",
        "*   Автомобиль үшін автопилотты оқыту.\n",
        "*   Шахмат немесе го (AlphaGo) ойнауға арналған алгоритмдерді құру.\n",
        "*   Зауыттағы робот-манипуляторды басқаруды оңтайландыру."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9521b8c",
      "metadata": {},
      "source": [
        "## 2. ML-жобасының өмірлік циклі (CRISP-DM негізінде)\n",
        "\n",
        "Кез келген маңызды ML-жобасы — бұл ретсіз әрекеттер жиынтығы емес, құрылымдалған, итеративті процесс. Оны ұйымдастырудың ең танымал әдістемелерінің бірі — **CRISP-DM (Cross-Industry Standard Process for Data Mining)**. Ол болжамдылықты, басқарылымдылықты және соңғы өнімнің жоғары сапасын қамтамасыз етуге көмектеседі."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c3675dd-revised",
      "metadata": {},
      "source": [
        "#### Өмірлік цикл кезеңдері:\n",
        "\n",
        "**1. Business Understanding (Бизнес-міндетті түсіну):**\n",
        "*   **Сұрақтар:** Біз бизнес үшін қандай мәселені шешеміз? Табыс қалай көрінеді? Оны қандай метрикалармен өлшеуге болады?\n",
        "*   **Мысал:** Міндет \"регрессия моделін құру\" емес, \"бағалау процесін жеделдету үшін пәтердің нарықтық құнын 10% дәлдікпен болжайтын риэлторларға арналған сервис құру\".\n",
        "*   **Нәтиже:** Жобаның нақты тұжырымдалған мақсаты және табыс критерийлері.\n",
        "\n",
        "**2. Data Understanding (Деректерді талдау):**\n",
        "*   **Әрекеттер:** Деректерді жинау, бастапқы зерттеу (EDA), статистикалар, үлестірімдер, корреляциялар, визуализациялар.\n",
        "*   **Мақсат:** Бізде қандай деректер бар екенін, олардың сапасы қандай екенін, оларда ауытқулар бар-жоғын және міндетті шешуге жеткілікті ме екенін түсіну.\n",
        "\n",
        "**3. Data Preparation (Деректерді дайындау):**\n",
        "*   **Маңыздылығы:** Бұл жоба уақытының 80%-на дейін алатын ең көп еңбекті қажет ететін кезең.\n",
        "*   **Әрекеттер:**\n",
        "    *   *Тазалау:* бос орындарды өңдеу, қайталанатын жазбаларды жою, шығарындылармен жұмыс.\n",
        "    *   *Белгілер инжинирингі (Feature Engineering):* бар белгілерден жаңа, ақпараттылығы жоғары белгілерді құру.\n",
        "    *   *Белгілерді іріктеу (Feature Selection):* ең маңызды белгілерді таңдау.\n",
        "    *   *Деректерді түрлендіру:* категориялық белгілерді кодтау, **сандық белгілерді масштабтау (бұл туралы толығырақ сөйлесетін боламыз)**.\n",
        "\n",
        "**4. Modeling (Модельдеу):**\n",
        "*   **Әрекеттер:** Алгоритмді таңдау, деректерді оқыту және тест іріктемелеріне бөлу, модельді оқыту, гиперпараметрлерді таңдау.\n",
        "\n",
        "**5. Evaluation (Модельді бағалау):**\n",
        "*   **Әрекеттер:** Оқытылған модельдің сапасын кейінге қалдырылған іріктемеде техникалық метрикалар көмегімен бағалау және оларды бизнес-критерийлермен салыстыру.\n",
        "\n",
        "**6. Deployment (Енгізу):**\n",
        "*   **Әрекеттер:** Дайын модельді қолданыстағы АТ-инфрақұрылымға интеграциялау.\n",
        "\n",
        "**Маңызды:** Бұл процесс **итеративті**. Көбінесе бағалау кезеңінен кейін нәтижені жақсарту үшін деректерді дайындауға немесе тіпті бизнес-міндетті түсінуге оралуға тура келеді."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454ff012-8de7-4f9d-bac6-0ee711aa6454-revised",
      "metadata": {},
      "source": [
        "### 2.1. Машиналық оқытудағы стандартты жұмыс процесі\n",
        "\n",
        "Келесі диаграмма модельді объективті бағалау үшін деректерді бөлудің маңыздылығын көрсетеді.\n",
        "\n",
        "1. **Деректерді бөлу:** Бастапқы деректер (`X` және `y`) **оқыту** және **тест** жиындарына бөлінеді. \n",
        "2. **Итеративті оқыту және баптау циклі:**  \n",
        "    * Модель тек *оқыту жиынында* **оқытылады**.  \n",
        "    * Модельдің сапасы **бағаланады** (көбінесе оқыту жиынының валидациялық бөлігінде).  \n",
        "    * Бағалау негізінде модельдің гиперпараметрлері **бапталады**.  \n",
        "    * Бұл цикл (`Оқыту -> Бағалау -> Баптау`) ең жақсы модель табылғанша қайталанады. \n",
        "3. **Қорытынды бағалау:** Баптау аяқталғаннан кейін, ең жақсы модель **тек бір рет** *тест жиынында* тексеріледі. Бұл деректерді модель оқыту немесе баптау процесінде ешқашан көрмеген. Бұл бізге оның өнімділігі туралы әділ, бейтарап баға береді. \n",
        "4. **Енгізу:** Егер тест нәтижелері қанағаттанарлық болса, модель енгізуге дайын.\n",
        "\n",
        "```mermaid\n",
        "graph LR\n",
        "    A[\"Деректер<br/>X және y\"] --> B[\"Оқыту<br/>деректер жиыны\"]\n",
        "    A --> C[\"Тест<br/>деректер жиыны\"]\n",
        "    \n",
        "    B --> D[\"Модельді<br/>оқыту<br/>(fit/train)\"]\n",
        "    D --> F[\"Модельдің<br/>жұмысын<br/>бағалау\"]\n",
        "    F -->|итерация| E[\"Модельді<br/>баптау\"]\n",
        "    E --> D\n",
        "    \n",
        "    C -->|қорытынды тексеру| F\n",
        "    E -->|ең жақсы модель| G[\"Модельді<br/>енгізу\"]\n",
        "    \n",
        "    %% Стильдерді анықтау\n",
        "    classDef data fill:#f8c471,stroke:#333,stroke-width:2px,color:#000\n",
        "    classDef training fill:#e5b4c4,stroke:#333,stroke-width:2px,color:#000\n",
        "    classDef eval fill:#c8e6c9,stroke:#333,stroke-width:2px,color:#000\n",
        "    classDef deploy fill:#d1c4e9,stroke:#333,stroke-width:2px,color:#000\n",
        "\n",
        "    %% Стильдерді қолдану\n",
        "    class A,B,C data\n",
        "    class D,E training\n",
        "    class F eval\n",
        "    class G deploy\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c6bda40-cd98-4079-97d2-f5de2e4e03d5-moved",
      "metadata": {},
      "source": [
        "### 2.2. Маңызды қадам: Белгілерді масштабтау (Feature Scaling)\n",
        "\n",
        "Масштабтау — деректерді дайындаудағы ең маңызды қадамдардың бірі. Көп жағдайда машиналық оқыту модельдерін \"шикі\", масштабталмаған деректерге қолдану қате болып табылады.\n",
        "\n",
        "#### Бұл не үшін қажет?\n",
        "\n",
        "Пәтер бағасын екі белгі бойынша болжап жатырмыз деп елестетіңіз:\n",
        "*   $x_1$: Бөлмелер саны (мәндері 1-ден 5-ке дейін)\n",
        "*   $x_2$: Шаршы метрдегі ауданы (мәндері 30-дан 200-ге дейін)\n",
        "\n",
        "Ауданның мәндер диапазоны бөлмелер санына қарағанда әлдеқайда үлкен. Көптеген алгоритмдер \"Аудан\" белгісін оның үлкен масштабына байланысты маңыздырақ деп қате санайтын болады.\n",
        "\n",
        "**Масштабтау барлық белгілерді салыстырмалы мәндер диапазонына келтіреді, осылайша олардың ешқайсысы өз масштабына байланысты басқаларынан басым болмайды.**\n",
        "\n",
        "Бұл келесілер үшін өте маңызды:\n",
        "1.  **Градиенттік түсуді қолданатын алгоритмдер (сызықтық модельдерді қоса алғанда):** Егер белгілердің масштабы әртүрлі болса, шығын функциясының \"ландшафты\" созылыңқы болады. Градиенттік түсуге минимумды табу үшін әлдеқайда көп қадам қажет болады.\n",
        "2.  **Реттеуі бар модельдер (Ridge, Lasso), оларды кейінірек зерттейміз:** Айыппұл коэффициенттердің шамасына байланысты, және масштабтаусыз ол әртүрлі белгілерге дұрыс қолданылмайды.\n",
        "3.  **Қашықтыққа негізделген алгоритмдер (мысалы, KNN, SVM):** Қашықтық ең үлкен масштабы бар белгімен толықтай анықталатын болады.\n",
        "\n",
        "#### Масштабтау тәсілдері\n",
        "\n",
        "1. **Стандарттау (Standardization)**\n",
        "\n",
        "Деректерді **орташа мәні 0 және стандартты ауытқуы 1** болатындай етіп түрлендіреді.\n",
        "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
        "*   **`scikit-learn`-де:** `StandardScaler()`\n",
        "*   **Қасиеттері:** Көптеген міндеттер үшін, соның ішінде сызықтық модельдер үшін **стандартты таңдау әдісі** болып табылады.\n",
        "\n",
        "2. **Нормализация (Normalization)**\n",
        "\n",
        "Деректерді **0-ден 1-ге дейінгі** диапазонға \"қысады\".\n",
        "$$ x_{scaled} = \\frac{x - x_{min}}{x_{max} - x_{min}} $$\n",
        "*   **`scikit-learn`-де:** `MinMaxScaler()`\n",
        "*   **Қасиеттері:** Кейбір алгоритмдерге (мысалы, нейрондық желілерге) пайдалы, бірақ шығарындыларға өте сезімтал.\n",
        "\n",
        "#### Масштабтаудың алтын ережесі\n",
        "\n",
        "Масштабтау параметрлері (орташа, std, min/max) **тек оқыту іріктемесінде** есептеліп, содан кейін оқыту және тест іріктемелеріне қолданылуы керек. Бұл **деректердің ағып кетуін (data leakage)** болдырмайды.\n",
        "\n",
        "```python\n",
        "# Дұрыс масштабтау мысалы\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Әрі қарай модель X_train_scaled-те оқытылып, X_test_scaled-те бағаланады\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4e0f3e6",
      "metadata": {},
      "source": [
        "## 3. Сызықтық регрессия: Тереңінен шолу\n",
        "\n",
        "**Міндет:** Үздіксіз нысаналы айнымалы `y` мәнін `X` белгілер жиынтығы негізінде болжау."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aaa52f3",
      "metadata": {},
      "source": [
        "### 3.1. Міндеттің математикалық қойылымы\n",
        "\n",
        "Бізде `n` нысаннан тұратын оқыту іріктемесі бар делік. Әрбір `i` нысаны үшін `m` белгі $(x_{i1}, x_{i2}, ..., x_{im})$ және нысаналы айнымалының $y_i$ мәні белгілі. Біз $y$-ті ең жақсы жуықтайтын $\\hat{y} = f(x_1, ..., x_m)$ функциясын тапқымыз келеді.\n",
        "\n",
        "Сызықтық регрессияда біз бұл тәуелділіктің **сызықты** екендігі туралы күшті, бірақ өте пайдалы болжам жасаймыз:\n",
        "$$ \\hat{y} = w_0 + w_1x_1 + w_2x_2 + ... + w_mx_m $$ \n",
        "\n",
        "*   $\\hat{y}$ — нысаналы айнымалының болжанған (модельдік) мәні.\n",
        "*   $w_0$ — **бос мүше (intercept)** немесе **ығысу (bias)**. Бұл барлық белгілер нөлге тең болғандағы $\\hat{y}$-тің базалық мәні.\n",
        "*   $w_1, ..., w_m$ — **модельдің салмақтары (коэффициенттері)**. Әрбір $w_j$ салмағы $x_j$ белгісі бір бірлікке артқанда, **қалған барлық белгілер өзгеріссіз қалған жағдайда**, $\\hat{y}$-тің орташа есеппен қаншаға өзгеретінін көрсетеді.\n",
        "\n",
        "Векторлық түрде бұл ықшамдалып жазылады. Егер біз белгілерімізге $x_0=1$ жалған белгісін қоссақ, онда формула келесідей болады:\n",
        "$$ \\hat{y} = \\sum_{j=0}^{m} w_j x_j = w^T x $$\n",
        "\n",
        "Ал бүкіл іріктеме үшін бірден:\n",
        "$$ \\hat{Y} = Xw $$\n",
        "\n",
        "Көрнекілік үшін синтетикалық деректерді генерациялайық."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "014a242d-f329-44d8-869e-4cde36979ad1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Демонстрация үшін қарапайым деректерді генерациялайық\n",
        "np.random.seed(42)\n",
        "X_simple = 2 * np.random.rand(100, 1)\n",
        "y_simple = 4 + 3 * X_simple + np.random.randn(100, 1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_simple, y_simple)\n",
        "plt.title('Регрессия міндетіне арналған деректер мысалы')\n",
        "plt.xlabel('X белгісі')\n",
        "plt.ylabel('y нысаналы айнымалысы')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vis_intro_lr_1",
      "metadata": {},
      "source": [
        "Идеалды әлемде деректер нүктелері бір түзудің бойында жатар еді. Біздің міндетіміз — жаңа X мәні бойынша Y мәнін болжау.\n",
        "\n",
        "![Идеалды сызықтық тәуелділік](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec6-1.png)\n",
        "\n",
        "Бірақ шын мәнінде деректерде әрқашан \"шу\" болады. Біз барлық нүктелер арқылы сызық жүргізе алмаймыз, бірақ оларға **ең жақын** өтетін сызықты таба аламыз.\n",
        "\n",
        "![Шулы нақты деректер](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec6-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2e758be-875f-4b4b-9282-44d3897a5df5-revised",
      "metadata": {},
      "source": [
        "### 3.2. \"Ең жақсы\" салмақтарды іздеу: шығын функциясы және Ең Кіші Квадраттар Әдісі (ЕККӘ)\n",
        "\n",
        "\"Ең жақсы\" $w$ салмақтарын қалай табуға болады? Машиналық оқытуда бұл сұрақ **шығын функциясын (Loss Function)** минимизациялау арқылы шешіледі. Ол модельдің болжамдары ($\\hat{y}$) оқыту деректеріндегі нақты мәндерден ($y$) қаншалықты қатты ерекшеленетінін өлшейді. Алгоритмнің міндеті — осы функцияның мәні минималды болатындай `w` салмақтарын таңдау.\n",
        "\n",
        "Классикалық сызықтық регрессия үшін негізгі шығын функциясы **Орташа Квадраттық Қате (Mean Squared Error, MSE)** болып табылады.\n",
        "\n",
        "$$ L(w) = MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2  \\rightarrow \\min_{w} $$\n",
        "\n",
        "MSE-ді минимизациялайтын `w` салмақтарын іздеу процесі **Ең Кіші Квадраттар Әдісі (ЕККӘ)** немесе **Ordinary Least Squares (OLS)** деп аталады.\n",
        "\n",
        "**Неліктен дәл MSE?**\n",
        "1.  **Дифференциалданатындығы:** MSE — тегіс, дифференциалданатын функция, бұл оның минимумын туындылар арқылы оңай табуға мүмкіндік береді.\n",
        "2.  **Үлкен қателер үшін айыппұл:** Квадратқа дәрежелеу үлкен қателіктер үшін модельді қатты \"жазалайды\".\n",
        "3.  **Бір ғана минимум:** MSE дөңес функция болып табылады, бұл оған жетуге болатын жалғыз ғаламдық минимумның болуын кепілдендіреді."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vis_residuals_1",
      "metadata": {},
      "source": [
        "ЕККӘ идеясы — нүктелер мен сызық арасындағы жалпы қашықтықты минимизациялау. Әрбір нүктеден сызыққа дейінгі қашықтық — бұл **қате** немесе **қалдық**.\n",
        "\n",
        "![Сызыққа дейінгі қашықтық ретіндегі қателер](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec6-3.png)\n",
        "\n",
        "Әртүрлі таңбалы қателер бір-бірін компенсацияламауы үшін біз оларды квадратқа дәрежелейміз. Біздің мақсатымыз — осы квадраттардың аудандарының қосындысын минимизациялау.\n",
        "\n",
        "![Қателер квадраттарының қосындысы](https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/figs/lec6-4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90e6034b-2359-4e6a-b479-d3aee23f2eef",
      "metadata": {},
      "source": [
        "Сызықтық регрессия жұмысының нәтижесін көрсетейік"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ee0c25-ee79-415c-af27-ad383ed83545",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_simple, y_simple)\n",
        "w0, w1 = lin_reg.intercept_[0], lin_reg.coef_[0][0]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_simple, y_simple)\n",
        "plt.plot(X_simple, lin_reg.predict(X_simple), color='red', linewidth=3, label='Регрессия сызығы')\n",
        "plt.title(f'Сызықтық регрессия жұмысының нәтижесі (y = {w0:.2f} + {w1:.2f}x)')\n",
        "plt.xlabel('X белгісі')\n",
        "plt.ylabel('y нысаналы айнымалысы')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9409394d-b4b5-43fc-916a-8aab988038ff",
      "metadata": {},
      "source": [
        "### 3.3. Модель сапасын бағалауға арналған метрикалар\n",
        "\n",
        "Модель оқытылды. Енді оның жақсы ма, жоқ па екенін түсінуіміз керек. Бұл үшін **сапа метрикалары (Evaluation Metrics)** қолданылады. Оқыту үшін алгоритмге қажет шығын функциясынан айырмашылығы, метрикалар **адамға нәтижені интерпретациялау** үшін қажет.\n",
        "\n",
        "Бағалау модель оқыту процесінде көрмеген (тесттік) деректерде жүргізіледі.\n",
        "\n",
        "1.  **MAE (Mean Absolute Error):** Орташа абсолюттік қате. \n",
        "    $$ MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i| $$\n",
        "    *   **Интерпретация:** \"Орташа есеппен біздің модель X бірлікке қателеседі\". Тапсырыс берушіге түсіндіру оңай.\n",
        "\n",
        "2.  **RMSE (Root Mean Squared Error):** Орташа квадраттық қатенің түбірі. \n",
        "    $$ RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2} $$\n",
        "    *   **Интерпретация:** Ең танымал метрика. Нысаналы айнымалымен бірдей бірлікте өлшенеді, бірақ сонымен бірге үлкен қателер үшін қатты жазалайды.\n",
        "\n",
        "3.  **R² (Детерминация коэффициенті):** Біздің модель нысаналы айнымалы `y` дисперсиясының қандай бөлігін түсіндіре алатынын көрсетеді. \n",
        "    $$ R^2 = 1 - \\frac{\\sum(y_i - \\hat{y}_i)^2}{\\sum(y_i - \\bar{y})^2} $$\n",
        "    *   **Интерпретация:** R² мәні 0-ден 1-ге дейін. 1-ге неғұрлым жақын болса, модель деректерді соғұрлым жақсы сипаттайды. $R^2 = 0.75$ модель нысаналы айнымалының өзгергіштігінің 75%-ын түсіндіретінін білдіреді. Салыстырмалы метрика болып табылады.\n",
        "    *   **Маңызды:** R² — бұл **тек сапа метрикасы**. Оны шығын функциясы ретінде пайдаланбайды."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdf5b2cb-ee83-49bf-b0e6-d974e29410f5",
      "metadata": {},
      "source": [
        "### 3.4. Шығын функциясы мен Сапа метрикаларын салыстыру\n",
        "\n",
        "Осы екі ұғымның айырмашылығын нақты түсіну маңызды.\n",
        "\n",
        "| Сипаттамасы        | Шығын функциясы (Loss Function)                          | Сапа метрикасы (Evaluation Metric)                             |\n",
        "| ------------------- | ---------------------------------------------------------- | ---------------------------------------------------------------- |\n",
        "| **Мақсаты**         | Модельді **оқыту** процесін басқару                       | **Оқытылған** модельдің өнімділігін бағалау                   |\n",
        "| **Кім \"қолданады\"** | Оңтайландыру **алгоритмі** (мысалы, градиенттік түсу)    | **Адам** (Data Scientist, тапсырыс беруші)                           |\n",
        "| **Негізгі қасиеті** | **Дифференциалданатын** болуы керек                      | **Интерпретацияланатын** және түсінікті болуы керек              |\n",
        "| **Қашан**           | Салмақтарды таңдау **кезінде** (`model.fit()`)              | Оқытудан **кейін**, жаңа деректерде бағалау үшін (`model.score()`) |\n",
        "| **СР үшін мысал**   | **MSE** — математикалық оңтайландыруға ыңғайлы.            | **RMSE** және **R²** — бизнес-нәтижені бағалау үшін түсінікті.    |\n",
        "\n",
        "**Қорытынды:** Сызықтық регрессия алгоритмі оқыту кезінде **MSE-ді минимизациялайды**. Біз, адамдар, оқытылған модельдің нақты өмірде қаншалықты жақсы жұмыс істейтінін бағалау үшін **RMSE мен R²-ге қараймыз**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fffc464",
      "metadata": {},
      "source": [
        "### 3.5. Сызықтық регрессияның маңызды болжамдары\n",
        "\n",
        "ЕККӘ көмегімен алынған $w$ коэффициенттерінің бағалары ығыспаған және тиімді, ал статистикалық қорытындылар (сенімділік аралықтары, p-value) — дұрыс болуы үшін бірнеше болжамдар орындалуы керек:\n",
        "\n",
        "1.  **Сызықтық:** Нысаналы айнымалының орташа мәні белгілерге сызықты тәуелді.\n",
        "2.  **Қателердің тәуелсіздігі:** $e_i$ қалдықтары бір-бірінен тәуелсіз болуы керек.\n",
        "3.  **Гомоскедастикалық (қателер дисперсиясының тұрақтылығы):** Қалдықтардың дисперсиясы барлық белгілер мәндері үшін бірдей болуы керек.\n",
        "4.  **Қателердің қалыпты үлестірілуі:** $e_i$ қалдықтары математикалық күтімі нөлге тең қалыпты үлестірілуі керек.\n",
        "5.  **Мультиколлинеарлықтың болмауы:** $X$ матрицасындағы белгілер бір-бірімен қатты корреляцияланбауы керек.\n",
        "\n",
        "Практикада бұл болжамдар жиі бұзылады, бірақ модель бәрібір сапасы жағынан қанағаттанарлық болжамдар бере алады. Алайда, сенімді және интерпретацияланатын модельдер құру үшін бұл шарттарды тексеру маңызды."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6279fc7d-revised",
      "metadata": {},
      "source": [
        "## 6-дәріс бойынша қорытынды\n",
        "\n",
        "Бүгін біз supervised learning-ді зерттеу үшін мықты негіз қаладық:\n",
        "1.  Регрессия міндетінің ML әлемінде қандай орын алатынын көрдік.\n",
        "2.  ML-жобасы — құрылымдалған инженерлік процесс (CRISP-DM) екенін түсіндік және деректерді дұрыс дайындаудың маңыздылығын ұғындық: іріктемелерге бөлу және масштабтау.\n",
        "3.  Сызықтық регрессияның математикасы мен жұмыс логикасын талдадық — орташа квадраттық қатені (MSE) минимизациялау арқылы ең жақсы сызықтық тәуелділікті іздейтін модель.\n",
        "4.  Шығын функциясын (машина үшін) сапа метрикаларынан (адам үшін) ажыратуды үйрендік және олардың негізгілерімен таныстық: MAE, RMSE және R².\n",
        "\n",
        "Келесі дәрісте біз сызықтық емес тәуелділіктерді сипаттау үшін моделімізді күрделендіріп, машиналық оқытудың негізгі мәселесімен — артық оқытумен (переобучение) бетпе-бет келеміз."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}