{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Семинар 9: Практическое применение KNN и SVM\n",
    "\n",
    "**Цель семинара:** На практике, шаг за шагом, разобрать полный цикл решения задачи бинарной классификации с помощью методов K-ближайших соседей (KNN) и Опорных векторов (SVM). Мы будем использовать библиотеку `scikit-learn`.\n",
    "\n",
    "**Задача:** Классификация подводных объектов по данным сонара. Нам нужно определить, является ли объект **миной (`M`)** или **камнем (`R`)** на основе 60 сигналов, полученных с сонара на разных частотах.\n",
    "\n",
    "**Почему этот датасет?**\n",
    "*   Это сложная задача бинарной классификации.\n",
    "*   Признаков много (60), и мы не можем просто визуализировать данные, чтобы \"увидеть\" решение.\n",
    "*   Данные не являются линейно разделимыми, что позволит нам увидеть мощь нелинейных ядер в SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1: Загрузка и первичный анализ данных\n",
    "\n",
    "**Что делаем:** Загружаем данные из файла и смотрим на их структуру. Убеждаемся, что нет пропусков, и понимаем, какого типа наши признаки и цель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загружаем данные. У этого файла нет заголовков, поэтому header=None.\n",
    "# Последний, 61-й столбец (индекс 60) - это наша цель.\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/yuliya-sabirova/ml-course/main/data/sonar.csv', header=None)\n",
    "\n",
    "# Посмотрим на первые 5 строк\n",
    "print(\"Первые 5 строк датасета:\")\n",
    "display(df.head())\n",
    "\n",
    "# Посмотрим на общую информацию и проверим пропуски\n",
    "print(\"\\nИнформация о датасете:\")\n",
    "df.info()\n",
    "\n",
    "# Посмотрим на баланс классов\n",
    "print(\"\\nБаланс классов (M - мина, R - камень):\")\n",
    "print(df[60].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы из первого шага:**\n",
    "*   Данные успешно загружены. У нас 208 объектов и 61 столбец.\n",
    "*   Все 60 признаков имеют числовой тип (`float64`).\n",
    "*   Целевая переменная (столбец 60) имеет тип `object` (строка).\n",
    "*   Пропусков в данных нет.\n",
    "*   Классы достаточно сбалансированы (111 Мин и 97 Камней), что хорошо для обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2: Подготовка данных для обучения\n",
    "\n",
    "**Что делаем:** Разделяем наши данные на матрицу признаков `X` и вектор целевой переменной `y`. Затем разбиваем их на обучающую и тестовую выборки. Это **ключевой** шаг для объективной оценки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X - это все столбцы, кроме последнего (признаки)\n",
    "X = df.drop(60, axis=1)\n",
    "\n",
    "# y - это последний столбец (цель)\n",
    "y = df[60]\n",
    "\n",
    "# Разделяем данные на обучающую (75%) и тестовую (25%) выборки\n",
    "# random_state=42 гарантирует, что разделение будет всегда одинаковым, \n",
    "# что позволяет воспроизводить результаты.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3: Создание и обучение модели KNN\n",
    "\n",
    "**Что делаем:** Мы будем использовать `Pipeline` и `GridSearchCV`. \n",
    "*   `Pipeline` — это конвейер, который позволяет объединить несколько шагов обработки в один. В нашем случае это будут 'масштабирование данных' -> 'модель KNN'. Это очень удобно и предотвращает утечку данных из тестовой выборки.\n",
    "*   `GridSearchCV` — инструмент для автоматического подбора лучших гиперпараметров. Мы зададим ему диапазон значений `k` (числа соседей), а он найдет оптимальное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Шаг 3.1: Создаем конвейер (Pipeline)\n",
    "# Первый шаг - 'scaler': стандартизация данных (приведение к среднему 0 и дисперсии 1)\n",
    "# Второй шаг - 'knn': наша модель\n",
    "knn_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Шаг 3.2: Определяем сетку параметров для поиска\n",
    "# Мы хотим, чтобы GridSearchCV перебрал все k от 1 до 29.\n",
    "# Название параметра 'knn__n_neighbors' состоит из имени шага в Pipeline ('knn'), \n",
    "# двух подчеркиваний '__' и названия параметра в модели ('n_neighbors').\n",
    "param_grid_knn = {'knn__n_neighbors': range(1, 30)}\n",
    "\n",
    "# Шаг 3.3: Создаем и обучаем GridSearchCV\n",
    "# cv=5 означает 5-кратную кросс-валидацию для оценки каждого параметра.\n",
    "grid_knn = GridSearchCV(knn_pipe, param_grid_knn, cv=5, scoring='accuracy')\n",
    "\n",
    "# Запускаем процесс обучения и подбора параметров\n",
    "grid_knn.fit(X_train, y_train)\n",
    "\n",
    "# Выводим лучший найденный параметр\n",
    "print(f\"Лучшее значение K для KNN: {grid_knn.best_params_['knn__n_neighbors']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4: Оценка качества модели KNN\n",
    "\n",
    "**Что делаем:** Используя лучшую модель, найденную `GridSearchCV`, делаем предсказания на тестовых данных и оцениваем их качество с помощью матрицы ошибок и отчета о классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred_knn = grid_knn.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Отчет по качеству модели KNN ---\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "print(\"Матрица ошибок для KNN:\")\n",
    "print(confusion_matrix(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Интерпретация результатов KNN:**\n",
    "*   `classification_report` показывает нам `precision`, `recall` и `f1-score` для каждого класса.\n",
    "*   `accuracy` (общая точность) показывает долю правильных ответов.\n",
    "*   Матрица ошибок показывает, какие классы модель путает. В данном случае, модель с k=1 ошиблась на 5 камнях (предсказала их как мины) и на 1 мине (предсказала как камень)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5: Создание, обучение и оценка модели SVM\n",
    "\n",
    "**Что делаем:** Повторяем тот же процесс, но теперь для модели SVM. Здесь мы будем подбирать уже другие гиперпараметры: `C` (штраф за ошибку) и `gamma` (влияние одного примера)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Шаг 5.1: Создаем Pipeline для SVM\n",
    "svm_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC())\n",
    "])\n",
    "\n",
    "# Шаг 5.2: Определяем сетку параметров для SVM\n",
    "# Мы переберем комбинации C и gamma. Ядро оставим 'rbf' - самое универсальное.\n",
    "param_grid_svm = {\n",
    "    'svm__C': [0.1, 1, 10, 50, 100],\n",
    "    'svm__gamma': ['scale', 'auto', 0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Шаг 5.3: Создаем и обучаем GridSearchCV для SVM\n",
    "grid_svm = GridSearchCV(svm_pipe, param_grid_svm, cv=5, scoring='accuracy')\n",
    "grid_svm.fit(X_train, y_train)\n",
    "\n",
    "# Выводим лучшие параметры\n",
    "print(f\"Лучшие параметры для SVM: {grid_svm.best_params_}\")\n",
    "\n",
    "# Шаг 5.4: Оценка лучшей модели SVM\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "print(\"\\n--- Отчет по качеству модели SVM ---\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "print(\"Матрица ошибок для SVM:\")\n",
    "print(confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6: Итоговое сравнение моделей\n",
    "\n",
    "**Что делаем:** Сводим результаты в одну таблицу или просто сравниваем отчеты, чтобы сделать вывод о том, какая модель лучше справилась с данной задачей.\n",
    "\n",
    "**Результаты:**\n",
    "\n",
    "| Метрика | KNN (k=1) | SVM (C=10, gamma='scale') |\n",
    "| :--- | :--- | :--- |\n",
    "| **Accuracy** | 0.90 | **0.94** |\n",
    "| **F1-score (M)** | 0.92 | **0.95** |\n",
    "| **F1-score (R)** | 0.89 | **0.93** |\n",
    "\n",
    "**Общий вывод семинара:**\n",
    "\n",
    "1.  Мы успешно реализовали полный цикл ML для двух разных моделей: от загрузки данных до оценки качества.\n",
    "2.  Мы увидели, насколько важен подбор гиперпараметров и как `GridSearchCV` автоматизирует этот процесс.\n",
    "3.  Мы убедились в необходимости использования `Pipeline` для корректного масштабирования данных.\n",
    "4.  В данной конкретной задаче, после подбора гиперпараметров, **модель SVM показала себя немного лучше**, чем KNN, по всем ключевым метрикам. Это часто бывает в задачах, где граница между классами сложная и нелинейная."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
